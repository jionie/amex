{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(\n",
    "    path=\"\", \n",
    "    usecols=None\n",
    "):\n",
    "    # LOAD DATAFRAME\n",
    "    if usecols is not None: \n",
    "        df = pd.read_parquet(path, columns=usecols)\n",
    "    else: \n",
    "        df = pd.read_parquet(path)\n",
    "    \n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    df[\"customer_ID\"] = df[\"customer_ID\"].str[-16:]\n",
    "    \n",
    "    hex_to_int = lambda x: int(x, 16)\n",
    "    df[[\"customer_ID\"]] = df[[\"customer_ID\"]].applymap(lambda x: int(x, 16))\n",
    "    \n",
    "    df[\"customer_ID\"] = df[\"customer_ID\"].astype(\"int64\")\n",
    "    df[\"S_2\"] = pd.to_datetime(df[\"S_2\"])\n",
    "    \n",
    "    # SORT BY CUSTOMER AND DATE (so agg(\"last\") works correctly)\n",
    "    df = df.sort_values([\"customer_ID\", \"S_2\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # FILL NAN\n",
    "    print(\"shape of data:\", df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "shape of data: (5531451, 190)\n",
      "shape of data: (11363762, 190)\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "TRAIN_PATH = \"../input/amex-data-integer-dtypes-parquet-format/train.parquet\"\n",
    "train = load_file(path = TRAIN_PATH)\n",
    "\n",
    "TEST_PATH = \"../input/amex-data-integer-dtypes-parquet-format/test.parquet\"\n",
    "test = load_file(path = TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['int_cols.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cols = train.select_dtypes(include=[np.int8, np.int16, np.int32, np.int64]).columns.tolist()\n",
    "int_cols = [col for col in int_cols if col not in [\"customer_ID\"]]\n",
    "dump(int_cols, \"int_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3053463\n",
       "1       476208\n",
       "3       103975\n",
       "2       102479\n",
       "4       101466\n",
       "        ...   \n",
       "178          1\n",
       "176          1\n",
       "149          1\n",
       "142          1\n",
       "172          1\n",
       "Name: D_39, Length: 180, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"D_39\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert to nan\n",
    "train[train==-1] = np.nan\n",
    "test[test==-1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>0.342033</td>\n",
       "      <td>9</td>\n",
       "      <td>0.298571</td>\n",
       "      <td>0.028331</td>\n",
       "      <td>0.506896</td>\n",
       "      <td>0.793958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.340178</td>\n",
       "      <td>16</td>\n",
       "      <td>0.353684</td>\n",
       "      <td>0.026975</td>\n",
       "      <td>0.505335</td>\n",
       "      <td>0.795727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825231</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>0.356010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.448582</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.506290</td>\n",
       "      <td>0.530133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>0.378665</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443752</td>\n",
       "      <td>0.024322</td>\n",
       "      <td>0.509069</td>\n",
       "      <td>0.539285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-07-22</td>\n",
       "      <td>0.416543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463824</td>\n",
       "      <td>0.023064</td>\n",
       "      <td>0.505335</td>\n",
       "      <td>0.461935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_ID        S_2       P_2  D_39       B_1       B_2  \\\n",
       "0 -9223358381327749917 2017-03-31  0.342033     9  0.298571  0.028331   \n",
       "1 -9223358381327749917 2017-04-07  0.340178    16  0.353684  0.026975   \n",
       "2 -9223358381327749917 2017-05-23  0.356010     1  0.448582  0.026601   \n",
       "3 -9223358381327749917 2017-06-22  0.378665     1  0.443752  0.024322   \n",
       "4 -9223358381327749917 2017-07-22  0.416543     1  0.463824  0.023064   \n",
       "\n",
       "        R_1       S_3  D_41       B_3  ...  D_136  D_137  D_138  D_139  D_140  \\\n",
       "0  0.506896  0.793958   0.0  0.823765  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "1  0.505335  0.795727   0.0  0.825231  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "2  0.506290  0.530133   0.0  0.923707  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "3  0.509069  0.539285   0.0  0.915724  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "4  0.505335  0.461935   0.0  0.919373  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "\n",
       "   D_141  D_142  D_143     D_144  D_145  \n",
       "0    0.0    NaN    0.0  0.004787    0.0  \n",
       "1    0.0    NaN    0.0  0.003442    0.0  \n",
       "2    0.0    NaN    0.0  0.003340    0.0  \n",
       "3    0.0    NaN    0.0  0.007556    0.0  \n",
       "4    0.0    NaN    0.0  0.005299    0.0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_observation(df):\n",
    "    \n",
    "    df[\"number_of_observations\"] = df.groupby(\"customer_ID\")[\"customer_ID\"].transform(\"count\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_observation(train)\n",
    "test = add_observation(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add first occurance flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_first_occurance(df):\n",
    "    \n",
    "    df[\"index\"] = df.index.tolist()\n",
    "    first_occurance_index = df[[\"customer_ID\", \"index\"]].groupby(\"customer_ID\").first()[\"index\"].tolist()\n",
    "    \n",
    "    df[\"first_occurance\"] = 0\n",
    "    df.loc[df[\"index\"].isin(first_occurance_index), \"first_occurance\"] = 1\n",
    "    \n",
    "    df = df.drop([\"index\"], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_first_occurance(train)\n",
    "test = add_first_occurance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nan clusters first\n",
    "cols = sorted(train.columns[2:].tolist())\n",
    "nas = train[cols].isna().sum(axis=0).reset_index(name=\"NA_count\")\n",
    "nas[\"group_count\"] = nas.loc[nas.NA_count > 0].groupby(\"NA_count\").transform(\"count\")\n",
    "clusters = nas.loc[nas.group_count > 10].sort_values([\"NA_count\",\"index\"]).groupby(\"NA_count\")[\"index\"].apply(list).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_16',\n",
       " 'B_19',\n",
       " 'B_2',\n",
       " 'B_20',\n",
       " 'B_22',\n",
       " 'B_26',\n",
       " 'B_27',\n",
       " 'B_3',\n",
       " 'B_30',\n",
       " 'B_33',\n",
       " 'B_38',\n",
       " 'D_41',\n",
       " 'D_54']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_113\n",
      "D_114\n",
      "D_116\n",
      "D_117\n",
      "D_120\n",
      "D_122\n",
      "D_123\n",
      "D_124\n",
      "D_125\n"
     ]
    }
   ],
   "source": [
    "for col in clusters[2]:\n",
    "    if col in int_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_0_nan(df, cluster):\n",
    "    \n",
    "    type_0_nan_customers = df.loc[df[cluster[0]].isnull(), \"customer_ID\"].unique().tolist()\n",
    "    df.loc[df[\"customer_ID\"].isin(type_0_nan_customers), cluster] = df.loc[df[\"customer_ID\"].isin(type_0_nan_customers), cluster].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = process_type_0_nan(train, clusters[0])\n",
    "# test = process_type_0_nan(test, clusters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_1_nan(df, cluster):\n",
    "    \n",
    "    type_1_nan_customers_group_0 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 0), \"customer_ID\"].unique().tolist()\n",
    "    type_1_nan_customers_group_1 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 1), \"customer_ID\"].unique().tolist()\n",
    "    \n",
    "    # fill group 1 by 0\n",
    "    df.loc[df[\"customer_ID\"].isin(type_1_nan_customers_group_1), cluster] = \\\n",
    "        df.loc[df[\"customer_ID\"].isin(type_1_nan_customers_group_1), cluster].fillna(0)\n",
    "    \n",
    "    # fill group 0 by mean of t - 1 and t + 1\n",
    "    ffill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    bfill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    \n",
    "    ffill[cluster] = ffill[cluster].fillna(method=\"ffill\")\n",
    "    bfill[cluster] = bfill[cluster].fillna(method=\"bfill\")\n",
    "    \n",
    "    df.loc[df[\"customer_ID\"].isin(type_1_nan_customers_group_0), cluster] = \\\n",
    "        (ffill.loc[ffill[\"customer_ID\"].isin(type_1_nan_customers_group_0), cluster] + \\\n",
    "         bfill.loc[bfill[\"customer_ID\"].isin(type_1_nan_customers_group_0), cluster]) / 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = process_type_1_nan(train, clusters[1])\n",
    "# test = process_type_1_nan(test, clusters[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_2_nan(df, cluster):\n",
    "    \n",
    "    type_2_nan_customers_group_0 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 0), \"customer_ID\"].unique().tolist()\n",
    "    type_2_nan_customers_group_1 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 1), \"customer_ID\"].unique().tolist()\n",
    "    \n",
    "    ffill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    bfill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    \n",
    "    ffill[cluster] = ffill[cluster].fillna(method=\"ffill\")\n",
    "    bfill[cluster] = bfill[cluster].fillna(method=\"bfill\")\n",
    "    \n",
    "    # fill group 1 by bfill\n",
    "    df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster] = \\\n",
    "        bfill.loc[bfill[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster]\n",
    "\n",
    "    # fill group 1 by 0\n",
    "    df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster] = \\\n",
    "        df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster].fillna(0)\n",
    "    \n",
    "    # fill group 0 by mean of fill and bfill\n",
    "    df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_0), cluster] = \\\n",
    "        (ffill.loc[ffill[\"customer_ID\"].isin(type_2_nan_customers_group_0), cluster] + \\\n",
    "         bfill.loc[bfill[\"customer_ID\"].isin(type_2_nan_customers_group_0), cluster]) / 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = process_type_2_nan(train, clusters[2])\n",
    "# test = process_type_2_nan(test, clusters[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_id(df):\n",
    "    \n",
    "    df[\"time_id\"] = df.groupby([\"customer_ID\"]).cumcount()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_time_id(train)\n",
    "test = add_time_id(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add end_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_year_month(df):\n",
    "    \n",
    "    df[\"end_year_month\"] = df[\"S_2\"].dt.to_period(\"M\")\n",
    "    df[\"end_year_month\"] = df.groupby(\"customer_ID\")[\"end_year_month\"].transform(\"last\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_end_year_month(train)\n",
    "test = add_end_year_month(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-04    5719469\n",
       "2019-10    5644293\n",
       "Freq: M, Name: end_year_month, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"end_year_month\"] .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_fillna.parquet\")\n",
    "# test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_fillna.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_base.parquet\")\n",
    "test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_base.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = load(\"int_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_fillna.parquet\")\n",
    "# test = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_fillna.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_base.parquet\")\n",
    "test = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_base.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_features = [\n",
    "    \"D_42\",\n",
    "    \"D_52\",\n",
    "    \"D_59\",\n",
    "    \"D_79\",\n",
    "    \"D_93\",\n",
    "    \"D_105\",\n",
    "    \"D_116\",\n",
    "    \"D_122\",\n",
    "    \"D_130\",\n",
    "    \"D_133\",\n",
    "    \"D_142\",\n",
    "    \"S_11\",\n",
    "    \"B_36\"\n",
    "]\n",
    "\n",
    "outlier_features = [\n",
    "    \"D_106\",\n",
    "    \"S_23\",\n",
    "    \"B_10\",\n",
    "]\n",
    "outlier_features = [feature for feature in outlier_features if feature not in int_cols]\n",
    "\n",
    "test_base_outlier_features = [\n",
    "    \"D_102\",\n",
    "    \"D_109\",\n",
    "    \"D_144\",\n",
    "    \"B_6\",\n",
    "    \"B_40\"\n",
    "]\n",
    "test_base_outlier_features = [feature for feature in test_base_outlier_features if feature not in int_cols]\n",
    "\n",
    "test_public_base_outlier_features = [\n",
    "    \"D_69\"\n",
    "]\n",
    "test_public_base_outlier_features = [feature for feature in test_public_base_outlier_features if feature not in int_cols]\n",
    "\n",
    "test_private_base_outlier_features = [\n",
    "    \"S_18\"\n",
    "]\n",
    "test_private_base_outlier_features = [feature for feature in test_private_base_outlier_features if feature not in int_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public_end_year_month = test[\"end_year_month\"].iloc[0]\n",
    "test_private_end_year_month = test[\"end_year_month\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_59\n",
      "D_79\n",
      "D_93\n",
      "D_116\n",
      "D_122\n",
      "S_11\n"
     ]
    }
   ],
   "source": [
    "for col in shift_features:\n",
    "    if col in int_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift features\n",
    "test.loc[test[\"end_year_month\"] == test_public_end_year_month, shift_features] = \\\n",
    "    test.loc[test[\"end_year_month\"] == test_public_end_year_month, shift_features] - \\\n",
    "    np.nanmean(test.loc[test[\"end_year_month\"] == test_public_end_year_month, shift_features], axis=0) + \\\n",
    "    np.nanmean(train[shift_features], axis=0)\n",
    "\n",
    "test.loc[test[\"end_year_month\"] == test_private_end_year_month, shift_features] = \\\n",
    "    test.loc[test[\"end_year_month\"] == test_private_end_year_month, shift_features] - \\\n",
    "    np.nanmean(test.loc[test[\"end_year_month\"] == test_private_end_year_month, shift_features], axis=0) + \\\n",
    "    np.nanmean(train[shift_features], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # int shift_features, floor\n",
    "# int_shift_features = [feature for feature in shift_features if feature in int_cols]\n",
    "\n",
    "# test[int_shift_features] = test[int_shift_features].fillna(-100)\n",
    "# test[int_shift_features] = np.floor(test[int_shift_features]).astype(int)\n",
    "\n",
    "# test[test==-100] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # float shift_features\n",
    "# float_shift_features = [feature for feature in shift_features if feature not in int_cols]\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_public_end_year_month, float_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_public_end_year_month, float_shift_features] - \\\n",
    "#     np.nanmean(test.loc[test[\"end_year_month\"] == test_public_end_year_month, float_shift_features], axis=0) + \\\n",
    "#     np.nanmean(train[float_shift_features], axis=0)\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_private_end_year_month, float_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_private_end_year_month, float_shift_features] - \\\n",
    "#     np.nanmean(test.loc[test[\"end_year_month\"] == test_private_end_year_month, float_shift_features], axis=0) + \\\n",
    "#     np.nanmean(train[float_shift_features], axis=0)\n",
    "\n",
    "# # int shift_features\n",
    "# int_shift_features = [feature for feature in shift_features if feature in int_cols]\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_public_end_year_month, int_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_public_end_year_month, int_shift_features] - \\\n",
    "#     np.floor(np.nanmean(test.loc[test[\"end_year_month\"] == test_public_end_year_month, int_shift_features], axis=0)).astype(int) + \\\n",
    "#     np.floor(np.nanmean(train[int_shift_features], axis=0)).astype(int)\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_private_end_year_month, int_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_private_end_year_month, int_shift_features] - \\\n",
    "#     np.floor(np.nanmean(test.loc[test[\"end_year_month\"] == test_private_end_year_month, int_shift_features], axis=0)).astype(int) + \\\n",
    "#     np.floor(np.nanmean(train[int_shift_features], axis=0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_shifted.parquet\")\n",
    "test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_shifted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_shifted.parquet\")\n",
    "# test = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_shifted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_public = test.loc[test[\"end_year_month\"] == test_public_end_year_month]\n",
    "# test_private = test.loc[test[\"end_year_month\"] == test_private_end_year_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # outlier_features\n",
    "# all_data = pd.concat([train, test], axis=0)\n",
    "\n",
    "# outlier_features_mean, outlier_features_std = np.nanmean(all_data[outlier_features], axis=0), np.nanstd(all_data[outlier_features], axis=0)\n",
    "\n",
    "# train[outlier_features] = np.clip(train[outlier_features], \n",
    "#                                   outlier_features_mean - 3 * outlier_features_std, \n",
    "#                                   outlier_features_mean + 3 * outlier_features_std\n",
    "#                                  )\n",
    "# test[outlier_features] = np.clip(test[outlier_features], \n",
    "#                                  outlier_features_mean - 3 * outlier_features_std, \n",
    "#                                  outlier_features_mean + 3 * outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_base_outlier_features\n",
    "# test_base_outlier_features_mean, test_base_outlier_features_std = \\\n",
    "#     np.nanmean(test[test_base_outlier_features], axis=0), np.nanstd(test[test_base_outlier_features], axis=0)\n",
    "\n",
    "# train[test_base_outlier_features] = np.clip(train[test_base_outlier_features], \n",
    "#                                   test_base_outlier_features_mean - 3 * test_base_outlier_features_std, \n",
    "#                                   test_base_outlier_features_mean + 3 * test_base_outlier_features_std\n",
    "#                                  )\n",
    "# test[test_base_outlier_features] = np.clip(test[test_base_outlier_features], \n",
    "#                                  test_base_outlier_features_mean - 3 * test_base_outlier_features_std, \n",
    "#                                  test_base_outlier_features_mean + 3 * test_base_outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_public_base_outlier_features\n",
    "# test_public_base_outlier_features_mean, test_public_base_outlier_features_std = \\\n",
    "#     np.nanmean(test_public[test_public_base_outlier_features], axis=0), np.nanstd(test_public[test_public_base_outlier_features], axis=0)\n",
    "\n",
    "# train[test_public_base_outlier_features] = np.clip(train[test_public_base_outlier_features], \n",
    "#                                   test_public_base_outlier_features_mean - 3 * test_public_base_outlier_features_std, \n",
    "#                                   test_public_base_outlier_features_mean + 3 * test_public_base_outlier_features_std\n",
    "#                                  )\n",
    "# test[test_public_base_outlier_features] = np.clip(test[test_public_base_outlier_features], \n",
    "#                                  test_public_base_outlier_features_mean - 3 * test_public_base_outlier_features_std, \n",
    "#                                  test_public_base_outlier_features_mean + 3 * test_public_base_outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_private_base_outlier_features\n",
    "# test_private_base_outlier_features_mean, test_private_base_outlier_features_std = \\\n",
    "#     np.nanmean(test_private[test_private_base_outlier_features], axis=0), np.nanstd(test_private[test_private_base_outlier_features], axis=0)\n",
    "\n",
    "# train[test_private_base_outlier_features] = np.clip(train[test_private_base_outlier_features], \n",
    "#                                   test_private_base_outlier_features_mean - 3 * test_private_base_outlier_features_std, \n",
    "#                                   test_private_base_outlier_features_mean + 3 * test_private_base_outlier_features_std\n",
    "#                                  )\n",
    "# test[test_private_base_outlier_features] = np.clip(test[test_private_base_outlier_features], \n",
    "#                                  test_private_base_outlier_features_mean - 3 * test_private_base_outlier_features_std, \n",
    "#                                  test_private_base_outlier_features_mean + 3 * test_private_base_outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.051987506, 0.18215398)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_base_outlier_features_mean[1], test_base_outlier_features_std[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_clipped.parquet\")\n",
    "# test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_clipped.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_feature_engineer(df):\n",
    "\n",
    "    all_cols = [c for c in list(df.columns) if c not in [\"customer_ID\", \"S_2\", \"first_occurance\", \"time_id\", \"end_year_month\"]]\n",
    "    nan_related_features = [\n",
    "        \"number_of_observations\",\n",
    "        \"type_0_nan\",\n",
    "        \"type_1_nan\",\n",
    "        \"type_2_nan\"\n",
    "    ]\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    num_features = [col for col in all_cols if col not in (cat_features + nan_related_features)]\n",
    "    \n",
    "    print(\"process num features\")\n",
    "    num_agg = df.groupby(\"customer_ID\")[num_features].agg([ \n",
    "        np.nanstd, \n",
    "        np.nanmin, \n",
    "        np.nanmax,\n",
    "        \"last\"\n",
    "    ])\n",
    "    num_agg.columns = [\"_\".join(x) for x in num_agg.columns]\n",
    "    print(\"num features shape:\", num_agg.shape)\n",
    "    \n",
    "    print(\"process sma num features\")\n",
    "    sma_num_agg_0 = df.loc[df[\"time_id\"] >= 0].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_0.columns = [(x + \"_nanmean_0\") for x in sma_num_agg_0.columns]\n",
    "    \n",
    "    sma_num_agg_4 = df.loc[df[\"time_id\"] >= 4].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_4.columns = [(x + \"_nanmean_4\") for x in sma_num_agg_4.columns]\n",
    "    \n",
    "    sma_num_agg_7 = df.loc[df[\"time_id\"] >= 7].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_7.columns = [(x + \"_nanmean_7\") for x in sma_num_agg_7.columns]\n",
    "    \n",
    "    sma_num_agg_10 = df.loc[df[\"time_id\"] >= 10].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_10.columns = [(x + \"_nanmean_10\") for x in sma_num_agg_10.columns]\n",
    "    \n",
    "    sma_num_agg = pd.concat([sma_num_agg_0, sma_num_agg_4, sma_num_agg_7, sma_num_agg_10], axis=1)\n",
    "    print(\"sma num features shape:\", sma_num_agg.shape)\n",
    "    \n",
    "    print(\"process cat features\")\n",
    "    cat_agg = df.groupby(\"customer_ID\")[cat_features].agg([\"count\", \"last\", \"nunique\"])\n",
    "    cat_agg.columns = [\"_\".join(x) for x in cat_agg.columns]\n",
    "    print(\"cat features shape:\", cat_agg.shape)\n",
    "    \n",
    "    df = pd.concat([num_agg, sma_num_agg, cat_agg], axis=1)\n",
    "    print(\"shape after engineering\", df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process num features\n",
      "num features shape: (458913, 708)\n",
      "process sma num features\n",
      "sma num features shape: (458913, 708)\n",
      "process cat features\n",
      "cat features shape: (458913, 33)\n",
      "shape after engineering (458913, 1449)\n",
      "process num features\n",
      "num features shape: (924621, 708)\n",
      "process sma num features\n",
      "sma num features shape: (924621, 708)\n",
      "process cat features\n",
      "cat features shape: (924621, 33)\n",
      "shape after engineering (924621, 1449)\n"
     ]
    }
   ],
   "source": [
    "train = process_and_feature_engineer(train)\n",
    "test = process_and_feature_engineer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_2_nanstd        7829\n",
       "P_2_nanmin        2434\n",
       "P_2_nanmax        2434\n",
       "P_2_last          2434\n",
       "D_39_nanstd       5120\n",
       "                 ...  \n",
       "D_66_last       399137\n",
       "D_66_nunique         0\n",
       "D_68_count           0\n",
       "D_68_last         5251\n",
       "D_68_nunique         0\n",
       "Length: 1449, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_nanstd</th>\n",
       "      <th>P_2_nanmin</th>\n",
       "      <th>P_2_nanmax</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_nanstd</th>\n",
       "      <th>D_39_nanmin</th>\n",
       "      <th>D_39_nanmax</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>B_1_nanstd</th>\n",
       "      <th>B_1_nanmin</th>\n",
       "      <th>...</th>\n",
       "      <th>D_63_nunique</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-9223358381327749917</th>\n",
       "      <td>0.057145</td>\n",
       "      <td>0.340178</td>\n",
       "      <td>0.498727</td>\n",
       "      <td>0.387708</td>\n",
       "      <td>4.628507</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>0.298571</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223193039457028513</th>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.964483</td>\n",
       "      <td>1.002478</td>\n",
       "      <td>1.001372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223189665817919541</th>\n",
       "      <td>0.038025</td>\n",
       "      <td>0.694073</td>\n",
       "      <td>0.828761</td>\n",
       "      <td>0.694073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223188534444851899</th>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.794826</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223173911659837606</th>\n",
       "      <td>0.078554</td>\n",
       "      <td>0.038207</td>\n",
       "      <td>0.252421</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>6.144625</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.105406</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      P_2_nanstd  P_2_nanmin  P_2_nanmax  P_2_last  \\\n",
       "customer_ID                                                          \n",
       "-9223358381327749917    0.057145    0.340178    0.498727  0.387708   \n",
       "-9223193039457028513    0.013094    0.964483    1.002478  1.001372   \n",
       "-9223189665817919541    0.038025    0.694073    0.828761  0.694073   \n",
       "-9223188534444851899    0.002688    0.786647    0.794826  0.787945   \n",
       "-9223173911659837606    0.078554    0.038207    0.252421  0.040486   \n",
       "\n",
       "                      D_39_nanstd  D_39_nanmin  D_39_nanmax  D_39_last  \\\n",
       "customer_ID                                                              \n",
       "-9223358381327749917     4.628507            0           16          0   \n",
       "-9223193039457028513     0.000000            0            0          0   \n",
       "-9223189665817919541     0.000000            0            0          0   \n",
       "-9223188534444851899     0.000000            0            0          0   \n",
       "-9223173911659837606     6.144625            0           17         13   \n",
       "\n",
       "                      B_1_nanstd  B_1_nanmin  ...  D_63_nunique  D_64_count  \\\n",
       "customer_ID                                   ...                             \n",
       "-9223358381327749917    0.048472    0.298571  ...             1          13   \n",
       "-9223193039457028513    0.001941    0.001238  ...             2          13   \n",
       "-9223189665817919541    0.002724    0.001909  ...             1          13   \n",
       "-9223188534444851899    0.002570    0.000845  ...             1          13   \n",
       "-9223173911659837606    0.005226    0.105406  ...             1          13   \n",
       "\n",
       "                      D_64_last  D_64_nunique  D_66_count  D_66_last  \\\n",
       "customer_ID                                                            \n",
       "-9223358381327749917        2.0             1           0        NaN   \n",
       "-9223193039457028513        0.0             1           0        NaN   \n",
       "-9223189665817919541        0.0             1           0        NaN   \n",
       "-9223188534444851899        3.0             2           0        NaN   \n",
       "-9223173911659837606        0.0             2           0        NaN   \n",
       "\n",
       "                      D_66_nunique  D_68_count  D_68_last  D_68_nunique  \n",
       "customer_ID                                                              \n",
       "-9223358381327749917             0          13        3.0             2  \n",
       "-9223193039457028513             0          13        6.0             1  \n",
       "-9223189665817919541             0          13        6.0             1  \n",
       "-9223188534444851899             0          13        5.0             1  \n",
       "-9223173911659837606             0          13        6.0             2  \n",
       "\n",
       "[5 rows x 1449 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df):\n",
    "    \n",
    "    targets = pd.read_csv(\"../input/train_labels.csv\")\n",
    "    \n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    targets[\"customer_ID\"] = targets[\"customer_ID\"].str[-16:]\n",
    "    \n",
    "    hex_to_int = lambda x: int(x, 16)\n",
    "    targets[[\"customer_ID\"]] = targets[[\"customer_ID\"]].applymap(lambda x: int(x, 16))\n",
    "    targets[\"customer_ID\"] = targets[\"customer_ID\"].astype(\"int64\")\n",
    "    \n",
    "    targets = targets.set_index(\"customer_ID\")\n",
    "    \n",
    "    df = df.merge(targets, left_index=True, right_index=True, how=\"left\")\n",
    "    df.target = df.target.astype(\"int8\")\n",
    "\n",
    "    # NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n",
    "    df = df.sort_index().reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_target(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 1451)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_nanstd</th>\n",
       "      <th>P_2_nanmin</th>\n",
       "      <th>P_2_nanmax</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_nanstd</th>\n",
       "      <th>D_39_nanmin</th>\n",
       "      <th>D_39_nanmax</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>B_1_nanstd</th>\n",
       "      <th>...</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>0.057145</td>\n",
       "      <td>0.340178</td>\n",
       "      <td>0.498727</td>\n",
       "      <td>0.387708</td>\n",
       "      <td>4.628507</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9223193039457028513</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.964483</td>\n",
       "      <td>1.002478</td>\n",
       "      <td>1.001372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9223189665817919541</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>0.694073</td>\n",
       "      <td>0.828761</td>\n",
       "      <td>0.694073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9223188534444851899</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.794826</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9223173911659837606</td>\n",
       "      <td>0.078554</td>\n",
       "      <td>0.038207</td>\n",
       "      <td>0.252421</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>6.144625</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_ID  P_2_nanstd  P_2_nanmin  P_2_nanmax  P_2_last  \\\n",
       "0 -9223358381327749917    0.057145    0.340178    0.498727  0.387708   \n",
       "1 -9223193039457028513    0.013094    0.964483    1.002478  1.001372   \n",
       "2 -9223189665817919541    0.038025    0.694073    0.828761  0.694073   \n",
       "3 -9223188534444851899    0.002688    0.786647    0.794826  0.787945   \n",
       "4 -9223173911659837606    0.078554    0.038207    0.252421  0.040486   \n",
       "\n",
       "   D_39_nanstd  D_39_nanmin  D_39_nanmax  D_39_last  B_1_nanstd  ...  \\\n",
       "0     4.628507            0           16          0    0.048472  ...   \n",
       "1     0.000000            0            0          0    0.001941  ...   \n",
       "2     0.000000            0            0          0    0.002724  ...   \n",
       "3     0.000000            0            0          0    0.002570  ...   \n",
       "4     6.144625            0           17         13    0.005226  ...   \n",
       "\n",
       "   D_64_count  D_64_last  D_64_nunique  D_66_count  D_66_last  D_66_nunique  \\\n",
       "0          13        2.0             1           0        NaN             0   \n",
       "1          13        0.0             1           0        NaN             0   \n",
       "2          13        0.0             1           0        NaN             0   \n",
       "3          13        3.0             2           0        NaN             0   \n",
       "4          13        0.0             2           0        NaN             0   \n",
       "\n",
       "   D_68_count  D_68_last  D_68_nunique  target  \n",
       "0          13        3.0             2       1  \n",
       "1          13        6.0             1       0  \n",
       "2          13        6.0             1       0  \n",
       "3          13        5.0             1       0  \n",
       "4          13        6.0             2       1  \n",
       "\n",
       "[5 rows x 1451 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df):\n",
    "    \n",
    "    cat_features_base = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ] \n",
    "    cat_features = [\n",
    "        \"{}_last\".format(feature) for feature in cat_features_base\n",
    "    ]\n",
    "    \n",
    "    for feature in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        df[feature] = encoder.fit_transform(df[feature])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = label_encoding(train)\n",
    "test = label_encoding(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"../input/train_base_shifted.parquet\")\n",
    "test.to_parquet(\"../input/test_base_shifted.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
