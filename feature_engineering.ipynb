{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(\n",
    "    path=\"\", \n",
    "    usecols=None\n",
    "):\n",
    "    # LOAD DATAFRAME\n",
    "    if usecols is not None: \n",
    "        df = pd.read_parquet(path, columns=usecols)\n",
    "    else: \n",
    "        df = pd.read_parquet(path)\n",
    "    \n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    df[\"customer_ID\"] = df[\"customer_ID\"].str[-16:]\n",
    "    \n",
    "    hex_to_int = lambda x: int(x, 16)\n",
    "    df[[\"customer_ID\"]] = df[[\"customer_ID\"]].applymap(lambda x: int(x, 16))\n",
    "    \n",
    "    df[\"customer_ID\"] = df[\"customer_ID\"].astype(\"int64\")\n",
    "    df[\"S_2\"] = pd.to_datetime(df[\"S_2\"])\n",
    "    \n",
    "    # SORT BY CUSTOMER AND DATE (so agg(\"last\") works correctly)\n",
    "    df = df.sort_values([\"customer_ID\", \"S_2\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # FILL NAN\n",
    "    print(\"shape of data:\", df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading data...\")\n",
    "TRAIN_PATH = \"../input/amex-data-integer-dtypes-parquet-format/train.parquet\"\n",
    "train = load_file(path = TRAIN_PATH)\n",
    "\n",
    "TEST_PATH = \"../input/amex-data-integer-dtypes-parquet-format/test.parquet\"\n",
    "test = load_file(path = TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert to nan\n",
    "train[train==-1] = np.nan\n",
    "test[test==-1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_observation(df):\n",
    "    \n",
    "    df[\"number_of_observations\"] = df.groupby(\"customer_ID\")[\"customer_ID\"].transform(\"count\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_observation(train)\n",
    "test = add_observation(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add first occurance flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_first_occurance(df):\n",
    "    \n",
    "    df[\"index\"] = df.index.tolist()\n",
    "    first_occurance_index = df[[\"customer_ID\", \"index\"]].groupby(\"customer_ID\").first()[\"index\"].tolist()\n",
    "    \n",
    "    df[\"first_occurance\"] = 0\n",
    "    df.loc[df[\"index\"].isin(first_occurance_index), \"first_occurance\"] = 1\n",
    "    \n",
    "    df = df.drop([\"index\"], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_first_occurance(train)\n",
    "test = add_first_occurance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nan clusters first\n",
    "cols = sorted(train.columns[2:].tolist())\n",
    "nas = train[cols].isna().sum(axis=0).reset_index(name=\"NA_count\")\n",
    "nas[\"group_count\"] = nas.loc[nas.NA_count > 0].groupby(\"NA_count\").transform(\"count\")\n",
    "clusters = nas.loc[nas.group_count > 10].sort_values([\"NA_count\",\"index\"]).groupby(\"NA_count\")[\"index\"].apply(list).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_0_nan(df, cluster):\n",
    "    \n",
    "    df[\"type_0_nan\"] = 0\n",
    "    df.loc[df[cluster[0]].isnull(), \"type_0_nan\"] = 1\n",
    "    df.loc[df[\"type_0_nan\"] == 1, cluster] = df.loc[df[\"type_0_nan\"] == 1, cluster].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_type_0_nan(train, clusters[0])\n",
    "test = process_type_0_nan(test, clusters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_1_nan(df, cluster):\n",
    "    \n",
    "    df[\"type_1_nan\"] = 0\n",
    "    df.loc[\n",
    "        (df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 1), \n",
    "        \"type_1_nan\"\n",
    "    ] = 1\n",
    "    df.loc[\n",
    "        (df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 0), \n",
    "        \"type_1_nan\"\n",
    "    ] = 2\n",
    "    \n",
    "    # fill type_1_nan == 1 by 0\n",
    "    df.loc[df[\"type_1_nan\"] == 1, cluster] = df.loc[df[\"type_1_nan\"] == 1, cluster].fillna(0)\n",
    "    \n",
    "    # fill type_1_nan == 0 by mean of t - 1 and t + 1\n",
    "    ffill = df[[\"customer_ID\", \"type_1_nan\"] + cluster].copy()\n",
    "    bfill = df[[\"customer_ID\", \"type_1_nan\"] + cluster].copy()\n",
    "    \n",
    "    ffill[cluster] = ffill[cluster].fillna(method=\"ffill\")\n",
    "    bfill[cluster] = bfill[cluster].fillna(method=\"bfill\")\n",
    "    \n",
    "    df.loc[df[\"type_1_nan\"] == 2, cluster] = (ffill.loc[ffill[\"type_1_nan\"] == 2, cluster] + \\\n",
    "                                              bfill.loc[ffill[\"type_1_nan\"] == 2, cluster]) / 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_type_1_nan(train, clusters[1])\n",
    "test = process_type_1_nan(test, clusters[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_2_nan(df, cluster):\n",
    "    \n",
    "    df[\"type_2_nan\"] = 0\n",
    "    df.loc[\n",
    "        (df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 1), \n",
    "        \"type_2_nan\"\n",
    "    ] = 1\n",
    "    df.loc[\n",
    "        (df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 0), \n",
    "        \"type_2_nan\"\n",
    "    ] = 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = process_type_2_nan(train, clusters[2])\n",
    "test = process_type_2_nan(test, clusters[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_id(df):\n",
    "    \n",
    "    df[\"time_id\"] = df.groupby([\"customer_ID\"]).cumcount()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_time_id(train)\n",
    "test = add_time_id(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add end_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_year_month(df):\n",
    "    \n",
    "    df[\"end_year_month\"] = df[\"S_2\"].dt.to_period(\"M\")\n",
    "    df[\"end_year_month\"] = df.groupby(\"customer_ID\")[\"end_year_month\"].transform(\"last\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_end_year_month(train)\n",
    "test = add_end_year_month(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"end_year_month\"] .value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature normalize by dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_fillna.parquet\")\n",
    "test = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_fillna.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [c for c in list(train.columns) if c not in [\"customer_ID\", \"S_2\", \"first_occurance\", \"time_id\", \"end_year_month\"]]\n",
    "nan_related_features = [\n",
    "    \"number_of_observations\",\n",
    "    \"type_0_nan\",\n",
    "    \"type_1_nan\",\n",
    "    \"type_2_nan\"\n",
    "]\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "num_features = [col for col in all_cols if col not in (cat_features + nan_related_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public_end_year_month = test[\"end_year_month\"].iloc[0]\n",
    "test_private_end_year_month = test[\"end_year_month\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[num_features] -= train.groupby(\"customer_ID\")[num_features].transform(\"first\")\n",
    "\n",
    "test.loc[test[\"end_year_month\"] == test_public_end_year_month, num_features] -= \\\n",
    "    test.loc[test[\"end_year_month\"] == test_public_end_year_month].groupby(\"customer_ID\")[num_features].transform(\"first\")\n",
    "\n",
    "test.loc[test[\"end_year_month\"] == test_private_end_year_month, num_features] -= \\\n",
    "    test.loc[test[\"end_year_month\"] == test_private_end_year_month].groupby(\"customer_ID\")[num_features].transform(\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_feature_engineer(df):\n",
    "\n",
    "    all_cols = [c for c in list(df.columns) if c not in [\"customer_ID\", \"S_2\", \"first_occurance\", \"time_id\", \"end_year_month\"]]\n",
    "    nan_related_features = [\n",
    "        \"number_of_observations\",\n",
    "        \"type_0_nan\",\n",
    "        \"type_1_nan\",\n",
    "        \"type_2_nan\"\n",
    "    ]\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    num_features = [col for col in all_cols if col not in (cat_features + nan_related_features)]\n",
    "    \n",
    "    print(\"process num features\")\n",
    "    num_agg = df.groupby(\"customer_ID\")[num_features].agg([ \n",
    "        np.nanstd, \n",
    "        np.nanmin, \n",
    "        np.nanmax,\n",
    "        \"last\"\n",
    "    ])\n",
    "    num_agg.columns = [\"_\".join(x) for x in num_agg.columns]\n",
    "    print(\"num features shape:\", num_agg.shape)\n",
    "    \n",
    "    print(\"process sma num features\")\n",
    "    sma_num_agg_0 = df.loc[df[\"time_id\"] >= 0].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_0.columns = [(x + \"_nanmean_0\") for x in sma_num_agg_0.columns]\n",
    "    \n",
    "    sma_num_agg_4 = df.loc[df[\"time_id\"] >= 4].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_4.columns = [(x + \"_nanmean_4\") for x in sma_num_agg_4.columns]\n",
    "    \n",
    "    sma_num_agg_7 = df.loc[df[\"time_id\"] >= 7].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_7.columns = [(x + \"_nanmean_7\") for x in sma_num_agg_7.columns]\n",
    "    \n",
    "    sma_num_agg_10 = df.loc[df[\"time_id\"] >= 10].groupby(\"customer_ID\")[num_features].agg(np.nanmean)\n",
    "    sma_num_agg_10.columns = [(x + \"_nanmean_10\") for x in sma_num_agg_10.columns]\n",
    "    \n",
    "    sma_num_agg = pd.concat([sma_num_agg_0, sma_num_agg_4, sma_num_agg_7, sma_num_agg_10], axis=1)\n",
    "    print(\"sma num features shape:\", sma_num_agg.shape)\n",
    "    \n",
    "    print(\"process cat features\")\n",
    "    cat_agg = df.groupby(\"customer_ID\")[cat_features].agg([\"count\", \"last\", \"nunique\"])\n",
    "    cat_agg.columns = [\"_\".join(x) for x in cat_agg.columns]\n",
    "    print(\"cat features shape:\", cat_agg.shape)\n",
    "    \n",
    "    df = pd.concat([num_agg, sma_num_agg, cat_agg], axis=1)\n",
    "    print(\"shape after engineering\", df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process num features\n",
      "num features shape: (458913, 708)\n",
      "process sma num features\n",
      "sma num features shape: (458913, 708)\n",
      "process cat features\n",
      "cat features shape: (458913, 33)\n",
      "shape after engineering (458913, 1449)\n",
      "process num features\n",
      "num features shape: (924621, 708)\n",
      "process sma num features\n",
      "sma num features shape: (924621, 708)\n",
      "process cat features\n",
      "cat features shape: (924621, 33)\n",
      "shape after engineering (924621, 1449)\n"
     ]
    }
   ],
   "source": [
    "train = process_and_feature_engineer(train)\n",
    "test = process_and_feature_engineer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_2_nanstd        7829\n",
       "P_2_nanmin        2434\n",
       "P_2_nanmax        2434\n",
       "P_2_last          2434\n",
       "D_39_nanstd       5120\n",
       "                 ...  \n",
       "D_66_last       399137\n",
       "D_66_nunique         0\n",
       "D_68_count           0\n",
       "D_68_last         5251\n",
       "D_68_nunique         0\n",
       "Length: 1449, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_nanstd</th>\n",
       "      <th>P_2_nanmin</th>\n",
       "      <th>P_2_nanmax</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_nanstd</th>\n",
       "      <th>D_39_nanmin</th>\n",
       "      <th>D_39_nanmax</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>B_1_nanstd</th>\n",
       "      <th>B_1_nanmin</th>\n",
       "      <th>...</th>\n",
       "      <th>D_63_nunique</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-9223358381327749917</th>\n",
       "      <td>0.057145</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>0.156693</td>\n",
       "      <td>0.045674</td>\n",
       "      <td>4.628507</td>\n",
       "      <td>-9</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223193039457028513</th>\n",
       "      <td>0.013094</td>\n",
       "      <td>-0.014827</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.022062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>-0.004207</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223189665817919541</th>\n",
       "      <td>0.038025</td>\n",
       "      <td>-0.118679</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>-0.118679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>-0.005812</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223188534444851899</th>\n",
       "      <td>0.002688</td>\n",
       "      <td>-0.007564</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9223173911659837606</th>\n",
       "      <td>0.078554</td>\n",
       "      <td>-0.214214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.211935</td>\n",
       "      <td>6.144625</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>-0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      P_2_nanstd  P_2_nanmin  P_2_nanmax  P_2_last  \\\n",
       "customer_ID                                                          \n",
       "-9223358381327749917    0.057145   -0.001855    0.156693  0.045674   \n",
       "-9223193039457028513    0.013094   -0.014827    0.023167  0.022062   \n",
       "-9223189665817919541    0.038025   -0.118679    0.016010 -0.118679   \n",
       "-9223188534444851899    0.002688   -0.007564    0.000614 -0.006266   \n",
       "-9223173911659837606    0.078554   -0.214214    0.000000 -0.211935   \n",
       "\n",
       "                      D_39_nanstd  D_39_nanmin  D_39_nanmax  D_39_last  \\\n",
       "customer_ID                                                              \n",
       "-9223358381327749917     4.628507           -9            7         -9   \n",
       "-9223193039457028513     0.000000            0            0          0   \n",
       "-9223189665817919541     0.000000            0            0          0   \n",
       "-9223188534444851899     0.000000            0            0          0   \n",
       "-9223173911659837606     6.144625            0           17         13   \n",
       "\n",
       "                      B_1_nanstd  B_1_nanmin  ...  D_63_nunique  D_64_count  \\\n",
       "customer_ID                                   ...                             \n",
       "-9223358381327749917    0.048472    0.000000  ...             1          13   \n",
       "-9223193039457028513    0.001941   -0.004207  ...             2          13   \n",
       "-9223189665817919541    0.002724   -0.005812  ...             1          13   \n",
       "-9223188534444851899    0.002570   -0.003348  ...             1          13   \n",
       "-9223173911659837606    0.005226   -0.003232  ...             1          13   \n",
       "\n",
       "                      D_64_last  D_64_nunique  D_66_count  D_66_last  \\\n",
       "customer_ID                                                            \n",
       "-9223358381327749917        2.0             1           0        NaN   \n",
       "-9223193039457028513        0.0             1           0        NaN   \n",
       "-9223189665817919541        0.0             1           0        NaN   \n",
       "-9223188534444851899        3.0             2           0        NaN   \n",
       "-9223173911659837606        0.0             2           0        NaN   \n",
       "\n",
       "                      D_66_nunique  D_68_count  D_68_last  D_68_nunique  \n",
       "customer_ID                                                              \n",
       "-9223358381327749917             0          13        3.0             2  \n",
       "-9223193039457028513             0          13        6.0             1  \n",
       "-9223189665817919541             0          13        6.0             1  \n",
       "-9223188534444851899             0          13        5.0             1  \n",
       "-9223173911659837606             0          13        6.0             2  \n",
       "\n",
       "[5 rows x 1449 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df):\n",
    "    \n",
    "    targets = pd.read_csv(\"../input/train_labels.csv\")\n",
    "    \n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    targets[\"customer_ID\"] = targets[\"customer_ID\"].str[-16:]\n",
    "    \n",
    "    hex_to_int = lambda x: int(x, 16)\n",
    "    targets[[\"customer_ID\"]] = targets[[\"customer_ID\"]].applymap(lambda x: int(x, 16))\n",
    "    targets[\"customer_ID\"] = targets[\"customer_ID\"].astype(\"int64\")\n",
    "    \n",
    "    targets = targets.set_index(\"customer_ID\")\n",
    "    \n",
    "    df = df.merge(targets, left_index=True, right_index=True, how=\"left\")\n",
    "    df.target = df.target.astype(\"int8\")\n",
    "\n",
    "    # NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n",
    "    df = df.sort_index().reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_target(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 1451)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_nanstd</th>\n",
       "      <th>P_2_nanmin</th>\n",
       "      <th>P_2_nanmax</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_nanstd</th>\n",
       "      <th>D_39_nanmin</th>\n",
       "      <th>D_39_nanmax</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>B_1_nanstd</th>\n",
       "      <th>...</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>0.057145</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>0.156693</td>\n",
       "      <td>0.045674</td>\n",
       "      <td>4.628507</td>\n",
       "      <td>-9</td>\n",
       "      <td>7</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9223193039457028513</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>-0.014827</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.022062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9223189665817919541</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>-0.118679</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>-0.118679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9223188534444851899</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>-0.007564</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9223173911659837606</td>\n",
       "      <td>0.078554</td>\n",
       "      <td>-0.214214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.211935</td>\n",
       "      <td>6.144625</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_ID  P_2_nanstd  P_2_nanmin  P_2_nanmax  P_2_last  \\\n",
       "0 -9223358381327749917    0.057145   -0.001855    0.156693  0.045674   \n",
       "1 -9223193039457028513    0.013094   -0.014827    0.023167  0.022062   \n",
       "2 -9223189665817919541    0.038025   -0.118679    0.016010 -0.118679   \n",
       "3 -9223188534444851899    0.002688   -0.007564    0.000614 -0.006266   \n",
       "4 -9223173911659837606    0.078554   -0.214214    0.000000 -0.211935   \n",
       "\n",
       "   D_39_nanstd  D_39_nanmin  D_39_nanmax  D_39_last  B_1_nanstd  ...  \\\n",
       "0     4.628507           -9            7         -9    0.048472  ...   \n",
       "1     0.000000            0            0          0    0.001941  ...   \n",
       "2     0.000000            0            0          0    0.002724  ...   \n",
       "3     0.000000            0            0          0    0.002570  ...   \n",
       "4     6.144625            0           17         13    0.005226  ...   \n",
       "\n",
       "   D_64_count  D_64_last  D_64_nunique  D_66_count  D_66_last  D_66_nunique  \\\n",
       "0          13        2.0             1           0        NaN             0   \n",
       "1          13        0.0             1           0        NaN             0   \n",
       "2          13        0.0             1           0        NaN             0   \n",
       "3          13        3.0             2           0        NaN             0   \n",
       "4          13        0.0             2           0        NaN             0   \n",
       "\n",
       "   D_68_count  D_68_last  D_68_nunique  target  \n",
       "0          13        3.0             2       1  \n",
       "1          13        6.0             1       0  \n",
       "2          13        6.0             1       0  \n",
       "3          13        5.0             1       0  \n",
       "4          13        6.0             2       1  \n",
       "\n",
       "[5 rows x 1451 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df):\n",
    "    \n",
    "    cat_features_base = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ] \n",
    "    cat_features = [\n",
    "        \"{}_last\".format(feature) for feature in cat_features_base\n",
    "    ]\n",
    "    \n",
    "    for feature in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        df[feature] = encoder.fit_transform(df[feature])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = label_encoding(train)\n",
    "test = label_encoding(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"../input/train_base_normalized.parquet\")\n",
    "test.to_parquet(\"../input/test_base_normalized.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
