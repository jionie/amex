{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/train_full_features.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_features = []\n",
    "\n",
    "exclude_features += [\n",
    "    \"customer_ID\", \n",
    "    \"target\",\n",
    "    \"number_of_observations\",\n",
    "    \"year_month\",\n",
    "]\n",
    "\n",
    "features = [col for col in train.columns if col not in exclude_features]\n",
    "\n",
    "cat_features_base = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "] \n",
    "cat_features = []\n",
    "for feature in features:\n",
    "    for cat_feature_base in cat_features_base:\n",
    "        if cat_feature_base in feature:\n",
    "            cat_features.append(feature)\n",
    "            \n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_stat_agg_group_1_to_del = load(\"base_stat_agg_group_1_to_del.pkl\")[0]\n",
    "base_stat_agg_group_2_to_del = load(\"base_stat_agg_group_2_to_del.pkl\")[0]\n",
    "base_stat_agg_to_del = base_stat_agg_group_1_to_del + base_stat_agg_group_2_to_del\n",
    "\n",
    "sma_agg_to_del = load(\"sma_agg_to_del.pkl\")[0]\n",
    "\n",
    "# quantile_agg_to_del = load(\"quantile_agg_to_del.pkl\")[0]\n",
    "quantile_agg_to_del = [feature for feature in features if \"quantile\" in feature]\n",
    "\n",
    "# skew_agg_to_del = load(\"skew_agg_to_del.pkl\")[0]\n",
    "# skew_agg_to_del = []\n",
    "skew_kurtosis_agg_to_del = load(\"skew_kurtosis_agg_to_del.pkl\")[0]\n",
    "skew_kurtosis_agg_to_del = [feature for feature in features if \"skew\" in feature] + \\\n",
    "    [feature for feature in features if \"kurtosis\" in feature]\n",
    "\n",
    "features = [feature for feature in features if feature not in (base_stat_agg_to_del + \\\n",
    "                                                               sma_agg_to_del + \\\n",
    "                                                               quantile_agg_to_del + \\\n",
    "                                                               skew_kurtosis_agg_to_del)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_folds = 5\n",
    "\n",
    "xgb_parms = { \n",
    "    \"max_depth\":4, \n",
    "    \"learning_rate\":0.05, \n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.6, \n",
    "    \"eval_metric\":\"logloss\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"tree_method\":\"gpu_hist\",\n",
    "    \"gpu_id\":1,\n",
    "    \"predictor\":\"gpu_predictor\",\n",
    "    \"random_state\":seed\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
    "class IterLoadForDMatrix(xgb.core.DataIter):\n",
    "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "        self.it = 0 # set iterator to 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        '''Reset the iterator'''\n",
    "        self.it = 0\n",
    "\n",
    "    def next(self, input_data):\n",
    "        '''Yield next batch of data.'''\n",
    "        if self.it == self.batches:\n",
    "            return 0 # Return 0 when there's no more batch.\n",
    "        \n",
    "        a = self.it * self.batch_size\n",
    "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
    "        dt = pd.DataFrame(self.df.iloc[a:b])\n",
    "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
    "        self.it += 1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train):\n",
    "\n",
    "    importances = []\n",
    "    \n",
    "    # create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=n_folds, \n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "        print(\"#\"*100)\n",
    "        print(\"Training fold {} with {} features...\".format(fold, len(features)))\n",
    "        \n",
    "        x_train= train.loc[trn_ind, features]\n",
    "        y_train= train.loc[trn_ind, target]\n",
    "        x_val = train.loc[val_ind, features]\n",
    "        y_val = train.loc[val_ind, target]\n",
    "\n",
    "        # xgb_train = xgb.DeviceQuantileDMatrix(xy_train, max_bin=256)\n",
    "        xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "        xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "\n",
    "        model = xgb.train(\n",
    "            xgb_parms, \n",
    "            dtrain=xgb_train,\n",
    "            evals=[(xgb_train,\"train\"),(xgb_val,\"valid\")],\n",
    "            num_boost_round=9999,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100\n",
    "        ) \n",
    "        model.save_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "        # importance\n",
    "        importance = model.get_score(importance_type=\"weight\")\n",
    "        importances.append(pd.DataFrame({\"feature\":importance.keys(), \"importance_{}\".format(fold):importance.values()}))\n",
    "\n",
    "        # oof\n",
    "        oof_preds = model.predict(xgb_val)\n",
    "        score = amex_metric_mod(y_val.values, oof_preds)\n",
    "        print(\"fold {} score is {}\".format(fold, score))\n",
    "        \n",
    "        # add to out of folds array\n",
    "        oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "        del x_train, y_train, x_val, y_val, xgb_train, xgb_val, model, importance, oof_preds\n",
    "        _ = gc.collect()\n",
    "    \n",
    "    # compute oof\n",
    "    score = amex_metric_mod(train[target], oof_predictions)\n",
    "    print(\"oof score is {}\".format(score))\n",
    "    \n",
    "    # create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({\"customer_ID\": train[\"customer_ID\"], \"target\": train[target], \"prediction\": oof_predictions})\n",
    "    oof_df.to_parquet(\"xgb_oof_{}.parquet\".format(seed))\n",
    "    \n",
    "    return importances, oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Training fold 0 with 945 features...\n",
      "[0]\ttrain-logloss:0.66203\tvalid-logloss:0.66207\n",
      "[100]\ttrain-logloss:0.23674\tvalid-logloss:0.23955\n",
      "[200]\ttrain-logloss:0.22237\tvalid-logloss:0.22752\n",
      "[300]\ttrain-logloss:0.21636\tvalid-logloss:0.22362\n",
      "[400]\ttrain-logloss:0.21228\tvalid-logloss:0.22147\n",
      "[500]\ttrain-logloss:0.20907\tvalid-logloss:0.22035\n",
      "[600]\ttrain-logloss:0.20639\tvalid-logloss:0.21956\n",
      "[700]\ttrain-logloss:0.20403\tvalid-logloss:0.21910\n",
      "[800]\ttrain-logloss:0.20179\tvalid-logloss:0.21869\n",
      "[900]\ttrain-logloss:0.19965\tvalid-logloss:0.21836\n",
      "[1000]\ttrain-logloss:0.19773\tvalid-logloss:0.21817\n",
      "[1100]\ttrain-logloss:0.19579\tvalid-logloss:0.21794\n",
      "[1200]\ttrain-logloss:0.19397\tvalid-logloss:0.21777\n",
      "[1300]\ttrain-logloss:0.19218\tvalid-logloss:0.21767\n",
      "[1400]\ttrain-logloss:0.19043\tvalid-logloss:0.21752\n",
      "[1500]\ttrain-logloss:0.18875\tvalid-logloss:0.21744\n",
      "[1600]\ttrain-logloss:0.18704\tvalid-logloss:0.21736\n",
      "[1700]\ttrain-logloss:0.18535\tvalid-logloss:0.21730\n",
      "[1800]\ttrain-logloss:0.18376\tvalid-logloss:0.21727\n",
      "[1900]\ttrain-logloss:0.18216\tvalid-logloss:0.21723\n",
      "[1982]\ttrain-logloss:0.18083\tvalid-logloss:0.21726\n",
      "fold 0 score is 0.7914581541688671\n",
      "####################################################################################################\n",
      "Training fold 1 with 945 features...\n",
      "[0]\ttrain-logloss:0.66200\tvalid-logloss:0.66206\n",
      "[100]\ttrain-logloss:0.23670\tvalid-logloss:0.23966\n",
      "[200]\ttrain-logloss:0.22229\tvalid-logloss:0.22742\n",
      "[300]\ttrain-logloss:0.21632\tvalid-logloss:0.22344\n",
      "[400]\ttrain-logloss:0.21225\tvalid-logloss:0.22137\n",
      "[500]\ttrain-logloss:0.20908\tvalid-logloss:0.22016\n",
      "[600]\ttrain-logloss:0.20641\tvalid-logloss:0.21944\n",
      "[700]\ttrain-logloss:0.20397\tvalid-logloss:0.21883\n",
      "[800]\ttrain-logloss:0.20171\tvalid-logloss:0.21847\n",
      "[900]\ttrain-logloss:0.19969\tvalid-logloss:0.21806\n",
      "[1000]\ttrain-logloss:0.19765\tvalid-logloss:0.21780\n",
      "[1100]\ttrain-logloss:0.19574\tvalid-logloss:0.21763\n",
      "[1200]\ttrain-logloss:0.19394\tvalid-logloss:0.21752\n",
      "[1300]\ttrain-logloss:0.19209\tvalid-logloss:0.21734\n",
      "[1400]\ttrain-logloss:0.19036\tvalid-logloss:0.21726\n",
      "[1500]\ttrain-logloss:0.18865\tvalid-logloss:0.21715\n",
      "[1600]\ttrain-logloss:0.18702\tvalid-logloss:0.21708\n",
      "[1700]\ttrain-logloss:0.18534\tvalid-logloss:0.21703\n",
      "[1800]\ttrain-logloss:0.18373\tvalid-logloss:0.21698\n",
      "[1900]\ttrain-logloss:0.18217\tvalid-logloss:0.21696\n",
      "[2000]\ttrain-logloss:0.18064\tvalid-logloss:0.21687\n"
     ]
    }
   ],
   "source": [
    "importances, oof_df = training(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importances[0].copy()\n",
    "for k in range(1, n_folds): \n",
    "    importance = importance.merge(importances[k], on=\"feature\", how=\"left\")\n",
    "    \n",
    "importance[\"importance\"] = importance.iloc[:,1:].mean(axis=1)\n",
    "importance = importance.sort_values(\"importance\",ascending=False)\n",
    "\n",
    "# importance.to_csv(\"xgb_feature_importance.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 50\n",
    "\n",
    "plt.figure(figsize=(10, n_features))\n",
    "plt.barh(np.arange(n_features, 0, -1), importance.importance.values[:n_features])\n",
    "plt.yticks(np.arange(n_features,0,-1), importance.feature.values[:n_features])\n",
    "plt.title(\"xgb feature importance - Top {}\".format(n_features))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_2 = [col for col in importance[\"feature\"] if \"target\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.loc[importance[\"feature\"].isin(P_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(train, features):\n",
    "    \n",
    "    permutation_importances = {}\n",
    "    \n",
    "    for feature in tqdm(features):\n",
    "        \n",
    "        oof_predictions = np.zeros(len(train))\n",
    "        \n",
    "        kfold = StratifiedKFold(\n",
    "            n_splits=n_folds, \n",
    "            shuffle=True, \n",
    "            random_state=seed\n",
    "        )\n",
    "    \n",
    "        for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "            x_val = train.loc[val_ind, features]\n",
    "            x_val[feature] = np.random.RandomState(seed=42).permutation(x_val[feature])\n",
    "            y_val = train.loc[val_ind, target]\n",
    "\n",
    "            xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "            \n",
    "            model = xgb.Booster()\n",
    "            model.load_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "            # oof\n",
    "            oof_preds = model.predict(xgb_val)\n",
    "            oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "            del x_val, y_val, xgb_val, model, oof_preds\n",
    "            _ = gc.collect()\n",
    "\n",
    "        # compute oof\n",
    "        score = amex_metric_mod(train[target], oof_predictions)\n",
    "        permutation_importances[feature] = score\n",
    "    \n",
    "        dump(permutation_importances, \"permutation_importances.pkl\")\n",
    "    \n",
    "    return permutation_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation_importances = permutation(train, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
