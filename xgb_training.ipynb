{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/train_sma_observation_mean.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_folds = 5\n",
    "\n",
    "permutation_importances = load(\"permutation_importances.pkl\")\n",
    "permutation_importances = sorted(permutation_importances.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "exclude_features = []\n",
    "# exclude_features = [feature for (feature, score) in permutation_importances if score > 0.7922]\n",
    "\n",
    "exclude_features += [\n",
    "    \"customer_ID\", \n",
    "    \"target\",\n",
    "]\n",
    "features = [col for col in train.columns if col not in exclude_features]\n",
    "target = \"target\"\n",
    "cat_features_base = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "] \n",
    "cat_features = [\n",
    "    \"{}_last\".format(feature) for feature in cat_features_base\n",
    "]\n",
    "\n",
    "xgb_parms = { \n",
    "    \"max_depth\":4, \n",
    "    \"learning_rate\":0.05, \n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.6, \n",
    "    \"eval_metric\":\"logloss\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"tree_method\":\"gpu_hist\",\n",
    "    \"gpu_id\":1,\n",
    "    \"predictor\":\"gpu_predictor\",\n",
    "    \"random_state\":seed\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
    "class IterLoadForDMatrix(xgb.core.DataIter):\n",
    "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "        self.it = 0 # set iterator to 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        '''Reset the iterator'''\n",
    "        self.it = 0\n",
    "\n",
    "    def next(self, input_data):\n",
    "        '''Yield next batch of data.'''\n",
    "        if self.it == self.batches:\n",
    "            return 0 # Return 0 when there's no more batch.\n",
    "        \n",
    "        a = self.it * self.batch_size\n",
    "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
    "        dt = pd.DataFrame(self.df.iloc[a:b])\n",
    "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
    "        self.it += 1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train):\n",
    "\n",
    "    importances = []\n",
    "    \n",
    "    # create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=n_folds, \n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "        print(\"#\"*100)\n",
    "        print(\"Training fold {} with {} features...\".format(fold, len(features)))\n",
    "        \n",
    "        x_train= train.loc[trn_ind, features]\n",
    "        y_train= train.loc[trn_ind, target]\n",
    "        x_val = train.loc[val_ind, features]\n",
    "        y_val = train.loc[val_ind, target]\n",
    "\n",
    "        # xgb_train = xgb.DeviceQuantileDMatrix(xy_train, max_bin=256)\n",
    "        xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "        xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "\n",
    "        model = xgb.train(\n",
    "            xgb_parms, \n",
    "            dtrain=xgb_train,\n",
    "            evals=[(xgb_train,\"train\"),(xgb_val,\"valid\")],\n",
    "            num_boost_round=9999,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100\n",
    "        ) \n",
    "        model.save_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "        # importance\n",
    "        importance = model.get_score(importance_type=\"weight\")\n",
    "        importances.append(pd.DataFrame({\"feature\":importance.keys(), \"importance_{}\".format(fold):importance.values()}))\n",
    "\n",
    "        # oof\n",
    "        oof_preds = model.predict(xgb_val)\n",
    "        score = amex_metric_mod(y_val.values, oof_preds)\n",
    "        print(\"fold {} score is {}\".format(fold, score))\n",
    "        \n",
    "        # add to out of folds array\n",
    "        oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "        del x_train, y_train, x_val, y_val, xgb_train, xgb_val, model, importance, oof_preds\n",
    "        _ = gc.collect()\n",
    "    \n",
    "    # compute oof\n",
    "    score = amex_metric_mod(train[target], oof_predictions)\n",
    "    print(\"oof score is {}\".format(score))\n",
    "    \n",
    "    # create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({\"customer_ID\": train[\"customer_ID\"], \"target\": train[target], \"prediction\": oof_predictions})\n",
    "    oof_df.to_parquet(\"xgb_oof_{}.parquet\".format(seed))\n",
    "    \n",
    "    return importances, oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Training fold 0 with 1626 features...\n",
      "[0]\ttrain-logloss:0.66245\tvalid-logloss:0.66253\n",
      "[100]\ttrain-logloss:0.23634\tvalid-logloss:0.23943\n",
      "[200]\ttrain-logloss:0.22167\tvalid-logloss:0.22730\n",
      "[300]\ttrain-logloss:0.21552\tvalid-logloss:0.22350\n",
      "[400]\ttrain-logloss:0.21125\tvalid-logloss:0.22156\n",
      "[500]\ttrain-logloss:0.20788\tvalid-logloss:0.22032\n",
      "[600]\ttrain-logloss:0.20502\tvalid-logloss:0.21961\n",
      "[700]\ttrain-logloss:0.20249\tvalid-logloss:0.21919\n",
      "[800]\ttrain-logloss:0.20011\tvalid-logloss:0.21882\n",
      "[900]\ttrain-logloss:0.19779\tvalid-logloss:0.21853\n",
      "[1000]\ttrain-logloss:0.19558\tvalid-logloss:0.21834\n",
      "[1100]\ttrain-logloss:0.19346\tvalid-logloss:0.21810\n",
      "[1200]\ttrain-logloss:0.19146\tvalid-logloss:0.21797\n",
      "[1300]\ttrain-logloss:0.18947\tvalid-logloss:0.21785\n",
      "[1400]\ttrain-logloss:0.18756\tvalid-logloss:0.21776\n",
      "[1500]\ttrain-logloss:0.18565\tvalid-logloss:0.21768\n",
      "[1600]\ttrain-logloss:0.18381\tvalid-logloss:0.21764\n",
      "[1700]\ttrain-logloss:0.18192\tvalid-logloss:0.21764\n",
      "[1800]\ttrain-logloss:0.18017\tvalid-logloss:0.21761\n",
      "[1890]\ttrain-logloss:0.17862\tvalid-logloss:0.21764\n",
      "fold 0 score is 0.7881777925248212\n",
      "####################################################################################################\n",
      "Training fold 1 with 1626 features...\n",
      "[0]\ttrain-logloss:0.66244\tvalid-logloss:0.66246\n",
      "[100]\ttrain-logloss:0.23609\tvalid-logloss:0.23933\n",
      "[200]\ttrain-logloss:0.22165\tvalid-logloss:0.22733\n",
      "[300]\ttrain-logloss:0.21544\tvalid-logloss:0.22351\n",
      "[400]\ttrain-logloss:0.21121\tvalid-logloss:0.22149\n",
      "[500]\ttrain-logloss:0.20792\tvalid-logloss:0.22030\n",
      "[600]\ttrain-logloss:0.20506\tvalid-logloss:0.21956\n",
      "[700]\ttrain-logloss:0.20240\tvalid-logloss:0.21905\n",
      "[800]\ttrain-logloss:0.19991\tvalid-logloss:0.21867\n",
      "[900]\ttrain-logloss:0.19761\tvalid-logloss:0.21836\n",
      "[1000]\ttrain-logloss:0.19537\tvalid-logloss:0.21816\n",
      "[1100]\ttrain-logloss:0.19322\tvalid-logloss:0.21800\n",
      "[1200]\ttrain-logloss:0.19115\tvalid-logloss:0.21791\n",
      "[1300]\ttrain-logloss:0.18916\tvalid-logloss:0.21779\n",
      "[1400]\ttrain-logloss:0.18722\tvalid-logloss:0.21777\n",
      "[1500]\ttrain-logloss:0.18529\tvalid-logloss:0.21774\n",
      "[1600]\ttrain-logloss:0.18345\tvalid-logloss:0.21772\n",
      "[1700]\ttrain-logloss:0.18162\tvalid-logloss:0.21766\n",
      "[1800]\ttrain-logloss:0.17974\tvalid-logloss:0.21763\n",
      "[1856]\ttrain-logloss:0.17873\tvalid-logloss:0.21764\n",
      "fold 1 score is 0.794373487984942\n",
      "####################################################################################################\n",
      "Training fold 2 with 1626 features...\n",
      "[0]\ttrain-logloss:0.66244\tvalid-logloss:0.66250\n",
      "[100]\ttrain-logloss:0.23625\tvalid-logloss:0.23944\n",
      "[200]\ttrain-logloss:0.22177\tvalid-logloss:0.22725\n",
      "[300]\ttrain-logloss:0.21557\tvalid-logloss:0.22327\n",
      "[400]\ttrain-logloss:0.21136\tvalid-logloss:0.22126\n",
      "[500]\ttrain-logloss:0.20797\tvalid-logloss:0.22010\n",
      "[600]\ttrain-logloss:0.20507\tvalid-logloss:0.21937\n",
      "[700]\ttrain-logloss:0.20246\tvalid-logloss:0.21888\n",
      "[800]\ttrain-logloss:0.20004\tvalid-logloss:0.21852\n",
      "[900]\ttrain-logloss:0.19778\tvalid-logloss:0.21825\n",
      "[1000]\ttrain-logloss:0.19560\tvalid-logloss:0.21803\n",
      "[1100]\ttrain-logloss:0.19344\tvalid-logloss:0.21789\n",
      "[1200]\ttrain-logloss:0.19139\tvalid-logloss:0.21775\n",
      "[1300]\ttrain-logloss:0.18939\tvalid-logloss:0.21763\n",
      "[1400]\ttrain-logloss:0.18744\tvalid-logloss:0.21753\n",
      "[1500]\ttrain-logloss:0.18556\tvalid-logloss:0.21742\n",
      "[1600]\ttrain-logloss:0.18372\tvalid-logloss:0.21732\n",
      "[1700]\ttrain-logloss:0.18181\tvalid-logloss:0.21727\n",
      "[1800]\ttrain-logloss:0.17997\tvalid-logloss:0.21726\n",
      "[1822]\ttrain-logloss:0.17959\tvalid-logloss:0.21727\n",
      "fold 2 score is 0.7915877089273913\n",
      "####################################################################################################\n",
      "Training fold 3 with 1626 features...\n",
      "[0]\ttrain-logloss:0.66247\tvalid-logloss:0.66251\n",
      "[100]\ttrain-logloss:0.23603\tvalid-logloss:0.23992\n",
      "[200]\ttrain-logloss:0.22144\tvalid-logloss:0.22817\n",
      "[300]\ttrain-logloss:0.21527\tvalid-logloss:0.22439\n",
      "[400]\ttrain-logloss:0.21109\tvalid-logloss:0.22247\n",
      "[500]\ttrain-logloss:0.20775\tvalid-logloss:0.22133\n",
      "[600]\ttrain-logloss:0.20492\tvalid-logloss:0.22067\n",
      "[700]\ttrain-logloss:0.20231\tvalid-logloss:0.22014\n",
      "[800]\ttrain-logloss:0.19989\tvalid-logloss:0.21976\n",
      "[900]\ttrain-logloss:0.19760\tvalid-logloss:0.21944\n",
      "[1000]\ttrain-logloss:0.19539\tvalid-logloss:0.21915\n",
      "[1100]\ttrain-logloss:0.19328\tvalid-logloss:0.21897\n",
      "[1200]\ttrain-logloss:0.19123\tvalid-logloss:0.21874\n",
      "[1300]\ttrain-logloss:0.18916\tvalid-logloss:0.21865\n",
      "[1400]\ttrain-logloss:0.18726\tvalid-logloss:0.21854\n",
      "[1500]\ttrain-logloss:0.18533\tvalid-logloss:0.21853\n",
      "[1600]\ttrain-logloss:0.18345\tvalid-logloss:0.21843\n",
      "[1700]\ttrain-logloss:0.18164\tvalid-logloss:0.21835\n",
      "[1800]\ttrain-logloss:0.17987\tvalid-logloss:0.21833\n",
      "[1900]\ttrain-logloss:0.17811\tvalid-logloss:0.21837\n",
      "[1904]\ttrain-logloss:0.17804\tvalid-logloss:0.21836\n",
      "fold 3 score is 0.7918879204693097\n",
      "####################################################################################################\n",
      "Training fold 4 with 1626 features...\n",
      "[0]\ttrain-logloss:0.66249\tvalid-logloss:0.66235\n",
      "[100]\ttrain-logloss:0.23676\tvalid-logloss:0.23671\n",
      "[200]\ttrain-logloss:0.22215\tvalid-logloss:0.22464\n",
      "[300]\ttrain-logloss:0.21593\tvalid-logloss:0.22097\n",
      "[400]\ttrain-logloss:0.21174\tvalid-logloss:0.21917\n",
      "[500]\ttrain-logloss:0.20847\tvalid-logloss:0.21814\n",
      "[600]\ttrain-logloss:0.20552\tvalid-logloss:0.21743\n",
      "[700]\ttrain-logloss:0.20292\tvalid-logloss:0.21701\n",
      "[800]\ttrain-logloss:0.20056\tvalid-logloss:0.21667\n",
      "[900]\ttrain-logloss:0.19826\tvalid-logloss:0.21645\n",
      "[1000]\ttrain-logloss:0.19608\tvalid-logloss:0.21627\n",
      "[1100]\ttrain-logloss:0.19399\tvalid-logloss:0.21614\n",
      "[1200]\ttrain-logloss:0.19191\tvalid-logloss:0.21605\n",
      "[1300]\ttrain-logloss:0.18990\tvalid-logloss:0.21595\n",
      "[1400]\ttrain-logloss:0.18788\tvalid-logloss:0.21589\n",
      "[1500]\ttrain-logloss:0.18596\tvalid-logloss:0.21586\n",
      "[1600]\ttrain-logloss:0.18407\tvalid-logloss:0.21585\n",
      "[1700]\ttrain-logloss:0.18225\tvalid-logloss:0.21581\n",
      "[1743]\ttrain-logloss:0.18145\tvalid-logloss:0.21580\n",
      "fold 4 score is 0.7936079267120553\n",
      "oof score is 0.7919800868541501\n"
     ]
    }
   ],
   "source": [
    "importances, oof_df = training(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importances[0].copy()\n",
    "for k in range(1, n_folds): \n",
    "    importance = importance.merge(importances[k], on=\"feature\", how=\"left\")\n",
    "    \n",
    "importance[\"importance\"] = importance.iloc[:,1:].mean(axis=1)\n",
    "importance = importance.sort_values(\"importance\",ascending=False)\n",
    "\n",
    "importance.to_csv(\"xgb_feature_importance.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 50\n",
    "\n",
    "plt.figure(figsize=(10, n_features))\n",
    "plt.barh(np.arange(n_features, 0, -1), importance.importance.values[:n_features])\n",
    "plt.yticks(np.arange(n_features,0,-1), importance.feature.values[:n_features])\n",
    "plt.title(\"xgb feature importance - Top {}\".format(n_features))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(train, features):\n",
    "    \n",
    "    permutation_importances = {}\n",
    "    \n",
    "    for feature in tqdm(features):\n",
    "        \n",
    "        oof_predictions = np.zeros(len(train))\n",
    "        \n",
    "        kfold = StratifiedKFold(\n",
    "            n_splits=n_folds, \n",
    "            shuffle=True, \n",
    "            random_state=seed\n",
    "        )\n",
    "    \n",
    "        for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "            x_val = train.loc[val_ind, features]\n",
    "            x_val[feature] = np.random.RandomState(seed=42).permutation(x_val[feature])\n",
    "            y_val = train.loc[val_ind, target]\n",
    "\n",
    "            xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "            \n",
    "            model = xgb.Booster()\n",
    "            model.load_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "            # oof\n",
    "            oof_preds = model.predict(xgb_val)\n",
    "            oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "            del x_val, y_val, xgb_val, model, oof_preds\n",
    "            _ = gc.collect()\n",
    "\n",
    "        # compute oof\n",
    "        score = amex_metric_mod(train[target], oof_predictions)\n",
    "        permutation_importances[feature] = score\n",
    "    \n",
    "        dump(permutation_importances, \"permutation_importances.pkl\")\n",
    "    \n",
    "    return permutation_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_importances = permutation(train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
