{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/train_sma_magic_D_39.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_folds = 5\n",
    "\n",
    "permutation_importances = load(\"permutation_importances.pkl\")\n",
    "permutation_importances = sorted(permutation_importances.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "exclude_features = []\n",
    "# exclude_features = [feature for (feature, score) in permutation_importances if score > 0.7922]\n",
    "\n",
    "exclude_features += [\n",
    "    \"customer_ID\", \n",
    "    \"target\",\n",
    "    \"number_of_observations\",\n",
    "    \"magic_D_39\"\n",
    "]\n",
    "features = [col for col in train.columns if col not in exclude_features]\n",
    "target = \"target\"\n",
    "cat_features_base = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "] \n",
    "cat_features = [\n",
    "    \"{}_last\".format(feature) for feature in cat_features_base\n",
    "]\n",
    "\n",
    "xgb_parms = { \n",
    "    \"max_depth\":4, \n",
    "    \"learning_rate\":0.05, \n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.6, \n",
    "    \"eval_metric\":\"logloss\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"tree_method\":\"gpu_hist\",\n",
    "    \"gpu_id\":1,\n",
    "    \"predictor\":\"gpu_predictor\",\n",
    "    \"random_state\":seed\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
    "class IterLoadForDMatrix(xgb.core.DataIter):\n",
    "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "        self.it = 0 # set iterator to 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        '''Reset the iterator'''\n",
    "        self.it = 0\n",
    "\n",
    "    def next(self, input_data):\n",
    "        '''Yield next batch of data.'''\n",
    "        if self.it == self.batches:\n",
    "            return 0 # Return 0 when there's no more batch.\n",
    "        \n",
    "        a = self.it * self.batch_size\n",
    "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
    "        dt = pd.DataFrame(self.df.iloc[a:b])\n",
    "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
    "        self.it += 1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train):\n",
    "\n",
    "    importances = []\n",
    "    \n",
    "    # create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=n_folds, \n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "        print(\"#\"*100)\n",
    "        print(\"Training fold {} with {} features...\".format(fold, len(features)))\n",
    "        \n",
    "        x_train= train.loc[trn_ind, features]\n",
    "        y_train= train.loc[trn_ind, target]\n",
    "        x_val = train.loc[val_ind, features]\n",
    "        y_val = train.loc[val_ind, target]\n",
    "\n",
    "        # xgb_train = xgb.DeviceQuantileDMatrix(xy_train, max_bin=256)\n",
    "        xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "        xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "\n",
    "        model = xgb.train(\n",
    "            xgb_parms, \n",
    "            dtrain=xgb_train,\n",
    "            evals=[(xgb_train,\"train\"),(xgb_val,\"valid\")],\n",
    "            num_boost_round=9999,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100\n",
    "        ) \n",
    "        model.save_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "        # importance\n",
    "        importance = model.get_score(importance_type=\"weight\")\n",
    "        importances.append(pd.DataFrame({\"feature\":importance.keys(), \"importance_{}\".format(fold):importance.values()}))\n",
    "\n",
    "        # oof\n",
    "        oof_preds = model.predict(xgb_val)\n",
    "        score = amex_metric_mod(y_val.values, oof_preds)\n",
    "        print(\"fold {} score is {}\".format(fold, score))\n",
    "        \n",
    "        # add to out of folds array\n",
    "        oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "        del x_train, y_train, x_val, y_val, xgb_train, xgb_val, model, importance, oof_preds\n",
    "        _ = gc.collect()\n",
    "    \n",
    "    # compute oof\n",
    "    score = amex_metric_mod(train[target], oof_predictions)\n",
    "    print(\"oof score is {}\".format(score))\n",
    "    \n",
    "    # create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({\"customer_ID\": train[\"customer_ID\"], \"target\": train[target], \"prediction\": oof_predictions})\n",
    "    oof_df.to_parquet(\"xgb_oof_{}.parquet\".format(seed))\n",
    "    \n",
    "    return importances, oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Training fold 0 with 1450 features...\n",
      "[0]\ttrain-logloss:0.66249\tvalid-logloss:0.66258\n",
      "[100]\ttrain-logloss:0.23621\tvalid-logloss:0.23920\n",
      "[200]\ttrain-logloss:0.22161\tvalid-logloss:0.22723\n",
      "[300]\ttrain-logloss:0.21542\tvalid-logloss:0.22347\n",
      "[400]\ttrain-logloss:0.21120\tvalid-logloss:0.22147\n",
      "[500]\ttrain-logloss:0.20787\tvalid-logloss:0.22030\n",
      "[600]\ttrain-logloss:0.20506\tvalid-logloss:0.21960\n",
      "[700]\ttrain-logloss:0.20249\tvalid-logloss:0.21908\n",
      "[800]\ttrain-logloss:0.20010\tvalid-logloss:0.21875\n",
      "[900]\ttrain-logloss:0.19774\tvalid-logloss:0.21846\n",
      "[1000]\ttrain-logloss:0.19554\tvalid-logloss:0.21818\n",
      "[1100]\ttrain-logloss:0.19349\tvalid-logloss:0.21805\n",
      "[1200]\ttrain-logloss:0.19144\tvalid-logloss:0.21795\n",
      "[1300]\ttrain-logloss:0.18944\tvalid-logloss:0.21785\n",
      "[1400]\ttrain-logloss:0.18745\tvalid-logloss:0.21773\n",
      "[1500]\ttrain-logloss:0.18557\tvalid-logloss:0.21770\n",
      "[1600]\ttrain-logloss:0.18374\tvalid-logloss:0.21763\n",
      "[1700]\ttrain-logloss:0.18188\tvalid-logloss:0.21760\n",
      "[1748]\ttrain-logloss:0.18101\tvalid-logloss:0.21762\n",
      "fold 0 score is 0.789084622080144\n",
      "####################################################################################################\n",
      "Training fold 1 with 1450 features...\n",
      "[0]\ttrain-logloss:0.66248\tvalid-logloss:0.66253\n",
      "[100]\ttrain-logloss:0.23624\tvalid-logloss:0.23944\n",
      "[200]\ttrain-logloss:0.22157\tvalid-logloss:0.22731\n",
      "[300]\ttrain-logloss:0.21535\tvalid-logloss:0.22341\n",
      "[400]\ttrain-logloss:0.21120\tvalid-logloss:0.22147\n",
      "[500]\ttrain-logloss:0.20793\tvalid-logloss:0.22031\n",
      "[600]\ttrain-logloss:0.20500\tvalid-logloss:0.21955\n",
      "[700]\ttrain-logloss:0.20242\tvalid-logloss:0.21898\n",
      "[800]\ttrain-logloss:0.19999\tvalid-logloss:0.21870\n",
      "[900]\ttrain-logloss:0.19768\tvalid-logloss:0.21840\n",
      "[1000]\ttrain-logloss:0.19557\tvalid-logloss:0.21825\n",
      "[1100]\ttrain-logloss:0.19344\tvalid-logloss:0.21807\n",
      "[1200]\ttrain-logloss:0.19136\tvalid-logloss:0.21792\n",
      "[1300]\ttrain-logloss:0.18936\tvalid-logloss:0.21780\n",
      "[1400]\ttrain-logloss:0.18746\tvalid-logloss:0.21781\n",
      "[1433]\ttrain-logloss:0.18682\tvalid-logloss:0.21782\n",
      "fold 1 score is 0.792830602770999\n",
      "####################################################################################################\n",
      "Training fold 2 with 1450 features...\n",
      "[0]\ttrain-logloss:0.66250\tvalid-logloss:0.66252\n",
      "[100]\ttrain-logloss:0.23631\tvalid-logloss:0.23925\n",
      "[200]\ttrain-logloss:0.22168\tvalid-logloss:0.22688\n",
      "[300]\ttrain-logloss:0.21549\tvalid-logloss:0.22295\n",
      "[400]\ttrain-logloss:0.21133\tvalid-logloss:0.22090\n",
      "[500]\ttrain-logloss:0.20800\tvalid-logloss:0.21974\n",
      "[600]\ttrain-logloss:0.20508\tvalid-logloss:0.21905\n",
      "[700]\ttrain-logloss:0.20251\tvalid-logloss:0.21861\n",
      "[800]\ttrain-logloss:0.20013\tvalid-logloss:0.21827\n",
      "[900]\ttrain-logloss:0.19775\tvalid-logloss:0.21806\n",
      "[1000]\ttrain-logloss:0.19555\tvalid-logloss:0.21792\n",
      "[1100]\ttrain-logloss:0.19342\tvalid-logloss:0.21773\n",
      "[1200]\ttrain-logloss:0.19138\tvalid-logloss:0.21759\n",
      "[1300]\ttrain-logloss:0.18945\tvalid-logloss:0.21747\n",
      "[1400]\ttrain-logloss:0.18748\tvalid-logloss:0.21738\n",
      "[1500]\ttrain-logloss:0.18555\tvalid-logloss:0.21739\n",
      "[1600]\ttrain-logloss:0.18373\tvalid-logloss:0.21738\n",
      "[1630]\ttrain-logloss:0.18317\tvalid-logloss:0.21737\n",
      "fold 2 score is 0.7913450733302962\n",
      "####################################################################################################\n",
      "Training fold 3 with 1450 features...\n",
      "[0]\ttrain-logloss:0.66252\tvalid-logloss:0.66259\n",
      "[100]\ttrain-logloss:0.23603\tvalid-logloss:0.23990\n",
      "[200]\ttrain-logloss:0.22132\tvalid-logloss:0.22788\n",
      "[300]\ttrain-logloss:0.21516\tvalid-logloss:0.22411\n",
      "[400]\ttrain-logloss:0.21101\tvalid-logloss:0.22225\n",
      "[500]\ttrain-logloss:0.20773\tvalid-logloss:0.22108\n",
      "[600]\ttrain-logloss:0.20488\tvalid-logloss:0.22032\n",
      "[700]\ttrain-logloss:0.20233\tvalid-logloss:0.21984\n",
      "[800]\ttrain-logloss:0.19998\tvalid-logloss:0.21946\n",
      "[900]\ttrain-logloss:0.19766\tvalid-logloss:0.21912\n",
      "[1000]\ttrain-logloss:0.19542\tvalid-logloss:0.21886\n",
      "[1100]\ttrain-logloss:0.19324\tvalid-logloss:0.21869\n",
      "[1200]\ttrain-logloss:0.19124\tvalid-logloss:0.21860\n",
      "[1300]\ttrain-logloss:0.18925\tvalid-logloss:0.21855\n",
      "[1400]\ttrain-logloss:0.18727\tvalid-logloss:0.21843\n",
      "[1500]\ttrain-logloss:0.18527\tvalid-logloss:0.21829\n",
      "[1600]\ttrain-logloss:0.18345\tvalid-logloss:0.21820\n",
      "[1700]\ttrain-logloss:0.18167\tvalid-logloss:0.21810\n",
      "[1800]\ttrain-logloss:0.17988\tvalid-logloss:0.21803\n",
      "[1900]\ttrain-logloss:0.17818\tvalid-logloss:0.21807\n",
      "[1946]\ttrain-logloss:0.17740\tvalid-logloss:0.21806\n",
      "fold 3 score is 0.7923280796331961\n",
      "####################################################################################################\n",
      "Training fold 4 with 1450 features...\n",
      "[0]\ttrain-logloss:0.66253\tvalid-logloss:0.66241\n",
      "[100]\ttrain-logloss:0.23689\tvalid-logloss:0.23702\n",
      "[200]\ttrain-logloss:0.22220\tvalid-logloss:0.22497\n",
      "[300]\ttrain-logloss:0.21593\tvalid-logloss:0.22128\n",
      "[400]\ttrain-logloss:0.21174\tvalid-logloss:0.21952\n",
      "[500]\ttrain-logloss:0.20844\tvalid-logloss:0.21850\n",
      "[600]\ttrain-logloss:0.20553\tvalid-logloss:0.21780\n",
      "[700]\ttrain-logloss:0.20292\tvalid-logloss:0.21734\n",
      "[800]\ttrain-logloss:0.20046\tvalid-logloss:0.21706\n",
      "[900]\ttrain-logloss:0.19819\tvalid-logloss:0.21683\n",
      "[1000]\ttrain-logloss:0.19598\tvalid-logloss:0.21663\n",
      "[1100]\ttrain-logloss:0.19392\tvalid-logloss:0.21656\n",
      "[1200]\ttrain-logloss:0.19183\tvalid-logloss:0.21648\n",
      "[1300]\ttrain-logloss:0.18985\tvalid-logloss:0.21636\n",
      "[1400]\ttrain-logloss:0.18785\tvalid-logloss:0.21631\n",
      "[1500]\ttrain-logloss:0.18598\tvalid-logloss:0.21627\n",
      "[1600]\ttrain-logloss:0.18414\tvalid-logloss:0.21633\n",
      "[1615]\ttrain-logloss:0.18385\tvalid-logloss:0.21634\n",
      "fold 4 score is 0.7911655368414439\n",
      "oof score is 0.7911813662811753\n"
     ]
    }
   ],
   "source": [
    "importances, oof_df = training(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importances[0].copy()\n",
    "for k in range(1, n_folds): \n",
    "    importance = importance.merge(importances[k], on=\"feature\", how=\"left\")\n",
    "    \n",
    "importance[\"importance\"] = importance.iloc[:,1:].mean(axis=1)\n",
    "importance = importance.sort_values(\"importance\",ascending=False)\n",
    "\n",
    "importance.to_csv(\"xgb_feature_importance.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_features = [col for col in importance.columns if \"magic\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance[magic_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 50\n",
    "\n",
    "plt.figure(figsize=(10, n_features))\n",
    "plt.barh(np.arange(n_features, 0, -1), importance.importance.values[:n_features])\n",
    "plt.yticks(np.arange(n_features,0,-1), importance.feature.values[:n_features])\n",
    "plt.title(\"xgb feature importance - Top {}\".format(n_features))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(train, features):\n",
    "    \n",
    "    permutation_importances = {}\n",
    "    \n",
    "    for feature in tqdm(features):\n",
    "        \n",
    "        oof_predictions = np.zeros(len(train))\n",
    "        \n",
    "        kfold = StratifiedKFold(\n",
    "            n_splits=n_folds, \n",
    "            shuffle=True, \n",
    "            random_state=seed\n",
    "        )\n",
    "    \n",
    "        for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "            x_val = train.loc[val_ind, features]\n",
    "            x_val[feature] = np.random.RandomState(seed=42).permutation(x_val[feature])\n",
    "            y_val = train.loc[val_ind, target]\n",
    "\n",
    "            xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "            \n",
    "            model = xgb.Booster()\n",
    "            model.load_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "            # oof\n",
    "            oof_preds = model.predict(xgb_val)\n",
    "            oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "            del x_val, y_val, xgb_val, model, oof_preds\n",
    "            _ = gc.collect()\n",
    "\n",
    "        # compute oof\n",
    "        score = amex_metric_mod(train[target], oof_predictions)\n",
    "        permutation_importances[feature] = score\n",
    "    \n",
    "        dump(permutation_importances, \"permutation_importances.pkl\")\n",
    "    \n",
    "    return permutation_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_importances = permutation(train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
