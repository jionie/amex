{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/train_base_shifted.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_features = []\n",
    "\n",
    "exclude_features += [\n",
    "    \"customer_ID\", \n",
    "    \"target\",\n",
    "    \"number_of_observations\",\n",
    "    \"year_month\",\n",
    "]\n",
    "# all_features = [col for col in train.columns if col not in exclude_features]\n",
    "\n",
    "\n",
    "# selected_feature_idxes = load(\"selected_feature_idxes.pkl\")\n",
    "# features = [all_features[feature_idx] for feature_idx in selected_feature_idxes]\n",
    "\n",
    "features = [col for col in train.columns if col not in exclude_features]\n",
    "features = [col for col in features if (\"D_66\" not in col) and (\"D_87\" not in col)]\n",
    "\n",
    "cat_features_base = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "] \n",
    "cat_features = []\n",
    "for feature in features:\n",
    "    for cat_feature_base in cat_features_base:\n",
    "        if cat_feature_base in feature:\n",
    "            cat_features.append(feature)\n",
    "            \n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_folds = 5\n",
    "\n",
    "xgb_parms = { \n",
    "    \"max_depth\":4, \n",
    "    \"learning_rate\":0.05, \n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.6, \n",
    "    \"eval_metric\":\"logloss\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"tree_method\":\"gpu_hist\",\n",
    "    \"gpu_id\":1,\n",
    "    \"predictor\":\"gpu_predictor\",\n",
    "    \"random_state\":seed\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
    "class IterLoadForDMatrix(xgb.core.DataIter):\n",
    "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "        self.it = 0 # set iterator to 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        '''Reset the iterator'''\n",
    "        self.it = 0\n",
    "\n",
    "    def next(self, input_data):\n",
    "        '''Yield next batch of data.'''\n",
    "        if self.it == self.batches:\n",
    "            return 0 # Return 0 when there's no more batch.\n",
    "        \n",
    "        a = self.it * self.batch_size\n",
    "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
    "        dt = pd.DataFrame(self.df.iloc[a:b])\n",
    "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
    "        self.it += 1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train):\n",
    "\n",
    "    importances = []\n",
    "    \n",
    "    # create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=n_folds, \n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "        print(\"#\"*100)\n",
    "        print(\"Training fold {} with {} features...\".format(fold, len(features)))\n",
    "        \n",
    "        x_train= train.loc[trn_ind, features]\n",
    "        y_train= train.loc[trn_ind, target]\n",
    "        x_val = train.loc[val_ind, features]\n",
    "        y_val = train.loc[val_ind, target]\n",
    "\n",
    "        # xgb_train = xgb.DeviceQuantileDMatrix(xy_train, max_bin=256)\n",
    "        xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "        xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "\n",
    "        model = xgb.train(\n",
    "            xgb_parms, \n",
    "            dtrain=xgb_train,\n",
    "            evals=[(xgb_train,\"train\"),(xgb_val,\"valid\")],\n",
    "            num_boost_round=9999,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100\n",
    "        ) \n",
    "        model.save_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "        # importance\n",
    "        importance = model.get_score(importance_type=\"weight\")\n",
    "        importances.append(pd.DataFrame({\"feature\":importance.keys(), \"importance_{}\".format(fold):importance.values()}))\n",
    "\n",
    "        # oof\n",
    "        oof_preds = model.predict(xgb_val)\n",
    "        score = amex_metric_mod(y_val.values, oof_preds)\n",
    "        print(\"fold {} score is {}\".format(fold, score))\n",
    "        \n",
    "        # add to out of folds array\n",
    "        oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "        del x_train, y_train, x_val, y_val, xgb_train, xgb_val, model, importance, oof_preds\n",
    "        _ = gc.collect()\n",
    "    \n",
    "    # compute oof\n",
    "    score = amex_metric_mod(train[target], oof_predictions)\n",
    "    print(\"oof score is {}\".format(score))\n",
    "    \n",
    "    # create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({\"customer_ID\": train[\"customer_ID\"], \"target\": train[target], \"prediction\": oof_predictions})\n",
    "    oof_df.to_parquet(\"xgb_oof_{}.parquet\".format(seed))\n",
    "    \n",
    "    return importances, oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Training fold 0 with 1438 features...\n",
      "[0]\ttrain-logloss:0.66266\tvalid-logloss:0.66272\n",
      "[100]\ttrain-logloss:0.23631\tvalid-logloss:0.23938\n",
      "[200]\ttrain-logloss:0.22175\tvalid-logloss:0.22709\n",
      "[300]\ttrain-logloss:0.21566\tvalid-logloss:0.22345\n",
      "[400]\ttrain-logloss:0.21152\tvalid-logloss:0.22151\n",
      "[500]\ttrain-logloss:0.20817\tvalid-logloss:0.22037\n",
      "[600]\ttrain-logloss:0.20535\tvalid-logloss:0.21973\n",
      "[700]\ttrain-logloss:0.20271\tvalid-logloss:0.21922\n",
      "[800]\ttrain-logloss:0.20031\tvalid-logloss:0.21885\n",
      "[900]\ttrain-logloss:0.19802\tvalid-logloss:0.21861\n",
      "[1000]\ttrain-logloss:0.19582\tvalid-logloss:0.21835\n",
      "[1100]\ttrain-logloss:0.19372\tvalid-logloss:0.21825\n",
      "[1200]\ttrain-logloss:0.19163\tvalid-logloss:0.21814\n",
      "[1300]\ttrain-logloss:0.18962\tvalid-logloss:0.21801\n",
      "[1400]\ttrain-logloss:0.18769\tvalid-logloss:0.21788\n",
      "[1500]\ttrain-logloss:0.18581\tvalid-logloss:0.21776\n",
      "[1600]\ttrain-logloss:0.18392\tvalid-logloss:0.21769\n",
      "[1700]\ttrain-logloss:0.18208\tvalid-logloss:0.21771\n",
      "[1747]\ttrain-logloss:0.18124\tvalid-logloss:0.21772\n",
      "fold 0 score is 0.7892897201804923\n",
      "####################################################################################################\n",
      "Training fold 1 with 1438 features...\n",
      "[0]\ttrain-logloss:0.66262\tvalid-logloss:0.66260\n",
      "[100]\ttrain-logloss:0.23638\tvalid-logloss:0.23949\n",
      "[200]\ttrain-logloss:0.22191\tvalid-logloss:0.22754\n",
      "[300]\ttrain-logloss:0.21571\tvalid-logloss:0.22379\n",
      "[400]\ttrain-logloss:0.21158\tvalid-logloss:0.22187\n",
      "[500]\ttrain-logloss:0.20827\tvalid-logloss:0.22065\n",
      "[600]\ttrain-logloss:0.20535\tvalid-logloss:0.21985\n",
      "[700]\ttrain-logloss:0.20279\tvalid-logloss:0.21938\n",
      "[800]\ttrain-logloss:0.20025\tvalid-logloss:0.21902\n",
      "[900]\ttrain-logloss:0.19799\tvalid-logloss:0.21876\n",
      "[1000]\ttrain-logloss:0.19585\tvalid-logloss:0.21853\n",
      "[1100]\ttrain-logloss:0.19373\tvalid-logloss:0.21833\n",
      "[1200]\ttrain-logloss:0.19169\tvalid-logloss:0.21821\n",
      "[1300]\ttrain-logloss:0.18962\tvalid-logloss:0.21807\n",
      "[1400]\ttrain-logloss:0.18767\tvalid-logloss:0.21806\n",
      "[1500]\ttrain-logloss:0.18577\tvalid-logloss:0.21800\n",
      "[1600]\ttrain-logloss:0.18392\tvalid-logloss:0.21796\n",
      "[1671]\ttrain-logloss:0.18259\tvalid-logloss:0.21794\n",
      "fold 1 score is 0.792666066811228\n",
      "####################################################################################################\n",
      "Training fold 2 with 1438 features...\n",
      "[0]\ttrain-logloss:0.66261\tvalid-logloss:0.66270\n",
      "[100]\ttrain-logloss:0.23641\tvalid-logloss:0.23947\n",
      "[200]\ttrain-logloss:0.22177\tvalid-logloss:0.22710\n",
      "[300]\ttrain-logloss:0.21558\tvalid-logloss:0.22320\n",
      "[400]\ttrain-logloss:0.21140\tvalid-logloss:0.22122\n",
      "[500]\ttrain-logloss:0.20804\tvalid-logloss:0.22008\n",
      "[600]\ttrain-logloss:0.20520\tvalid-logloss:0.21937\n",
      "[700]\ttrain-logloss:0.20260\tvalid-logloss:0.21895\n",
      "[800]\ttrain-logloss:0.20020\tvalid-logloss:0.21858\n",
      "[900]\ttrain-logloss:0.19789\tvalid-logloss:0.21831\n",
      "[1000]\ttrain-logloss:0.19570\tvalid-logloss:0.21807\n",
      "[1100]\ttrain-logloss:0.19360\tvalid-logloss:0.21793\n",
      "[1200]\ttrain-logloss:0.19158\tvalid-logloss:0.21785\n",
      "[1300]\ttrain-logloss:0.18956\tvalid-logloss:0.21776\n",
      "[1400]\ttrain-logloss:0.18767\tvalid-logloss:0.21777\n",
      "[1500]\ttrain-logloss:0.18576\tvalid-logloss:0.21771\n",
      "[1600]\ttrain-logloss:0.18393\tvalid-logloss:0.21767\n",
      "[1655]\ttrain-logloss:0.18294\tvalid-logloss:0.21765\n",
      "fold 2 score is 0.7938125931697047\n",
      "####################################################################################################\n",
      "Training fold 3 with 1438 features...\n",
      "[0]\ttrain-logloss:0.66264\tvalid-logloss:0.66277\n",
      "[100]\ttrain-logloss:0.23616\tvalid-logloss:0.24019\n",
      "[200]\ttrain-logloss:0.22160\tvalid-logloss:0.22834\n",
      "[300]\ttrain-logloss:0.21547\tvalid-logloss:0.22450\n",
      "[400]\ttrain-logloss:0.21133\tvalid-logloss:0.22257\n",
      "[500]\ttrain-logloss:0.20802\tvalid-logloss:0.22137\n",
      "[600]\ttrain-logloss:0.20517\tvalid-logloss:0.22062\n",
      "[700]\ttrain-logloss:0.20263\tvalid-logloss:0.22007\n",
      "[800]\ttrain-logloss:0.20024\tvalid-logloss:0.21976\n",
      "[900]\ttrain-logloss:0.19802\tvalid-logloss:0.21951\n",
      "[1000]\ttrain-logloss:0.19581\tvalid-logloss:0.21933\n",
      "[1100]\ttrain-logloss:0.19365\tvalid-logloss:0.21915\n",
      "[1200]\ttrain-logloss:0.19160\tvalid-logloss:0.21891\n",
      "[1300]\ttrain-logloss:0.18967\tvalid-logloss:0.21877\n",
      "[1400]\ttrain-logloss:0.18770\tvalid-logloss:0.21868\n",
      "[1500]\ttrain-logloss:0.18580\tvalid-logloss:0.21858\n",
      "[1600]\ttrain-logloss:0.18395\tvalid-logloss:0.21850\n",
      "[1700]\ttrain-logloss:0.18216\tvalid-logloss:0.21847\n",
      "[1800]\ttrain-logloss:0.18042\tvalid-logloss:0.21843\n",
      "[1900]\ttrain-logloss:0.17862\tvalid-logloss:0.21842\n",
      "[2000]\ttrain-logloss:0.17684\tvalid-logloss:0.21845\n",
      "[2024]\ttrain-logloss:0.17644\tvalid-logloss:0.21845\n",
      "fold 3 score is 0.7933415689166519\n",
      "####################################################################################################\n",
      "Training fold 4 with 1438 features...\n",
      "[0]\ttrain-logloss:0.66269\tvalid-logloss:0.66259\n",
      "[100]\ttrain-logloss:0.23702\tvalid-logloss:0.23710\n",
      "[200]\ttrain-logloss:0.22221\tvalid-logloss:0.22476\n",
      "[300]\ttrain-logloss:0.21602\tvalid-logloss:0.22111\n",
      "[400]\ttrain-logloss:0.21186\tvalid-logloss:0.21930\n",
      "[500]\ttrain-logloss:0.20856\tvalid-logloss:0.21824\n",
      "[600]\ttrain-logloss:0.20568\tvalid-logloss:0.21757\n",
      "[700]\ttrain-logloss:0.20305\tvalid-logloss:0.21712\n",
      "[800]\ttrain-logloss:0.20065\tvalid-logloss:0.21684\n",
      "[900]\ttrain-logloss:0.19845\tvalid-logloss:0.21658\n",
      "[1000]\ttrain-logloss:0.19621\tvalid-logloss:0.21637\n",
      "[1100]\ttrain-logloss:0.19412\tvalid-logloss:0.21621\n",
      "[1200]\ttrain-logloss:0.19209\tvalid-logloss:0.21616\n",
      "[1300]\ttrain-logloss:0.19012\tvalid-logloss:0.21606\n",
      "[1400]\ttrain-logloss:0.18816\tvalid-logloss:0.21601\n",
      "[1500]\ttrain-logloss:0.18632\tvalid-logloss:0.21600\n",
      "[1600]\ttrain-logloss:0.18441\tvalid-logloss:0.21601\n",
      "[1700]\ttrain-logloss:0.18256\tvalid-logloss:0.21594\n",
      "[1800]\ttrain-logloss:0.18076\tvalid-logloss:0.21596\n",
      "[1857]\ttrain-logloss:0.17981\tvalid-logloss:0.21596\n",
      "fold 4 score is 0.7945368278461149\n",
      "oof score is 0.7927543505033878\n"
     ]
    }
   ],
   "source": [
    "importances, oof_df = training(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = importances[0].copy()\n",
    "for k in range(1, n_folds): \n",
    "    importance = importance.merge(importances[k], on=\"feature\", how=\"left\")\n",
    "    \n",
    "importance[\"importance\"] = importance.iloc[:,1:].mean(axis=1)\n",
    "importance = importance.sort_values(\"importance\",ascending=False)\n",
    "\n",
    "importance.to_csv(\"xgb_feature_importance.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 50\n",
    "\n",
    "plt.figure(figsize=(10, n_features))\n",
    "plt.barh(np.arange(n_features, 0, -1), importance.importance.values[:n_features])\n",
    "plt.yticks(np.arange(n_features,0,-1), importance.feature.values[:n_features])\n",
    "plt.title(\"xgb feature importance - Top {}\".format(n_features))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(train, features):\n",
    "    \n",
    "    permutation_importances = {}\n",
    "    \n",
    "    for feature in tqdm(features):\n",
    "        \n",
    "        oof_predictions = np.zeros(len(train))\n",
    "        \n",
    "        kfold = StratifiedKFold(\n",
    "            n_splits=n_folds, \n",
    "            shuffle=True, \n",
    "            random_state=seed\n",
    "        )\n",
    "    \n",
    "        for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "\n",
    "            x_val = train.loc[val_ind, features]\n",
    "            x_val[feature] = np.random.RandomState(seed=42).permutation(x_val[feature])\n",
    "            y_val = train.loc[val_ind, target]\n",
    "\n",
    "            xgb_val = xgb.DMatrix(data=x_val, label=y_val)\n",
    "            \n",
    "            model = xgb.Booster()\n",
    "            model.load_model(\"../ckpt/xgb_{}_{}.xgb\".format(fold, seed))\n",
    "\n",
    "            # oof\n",
    "            oof_preds = model.predict(xgb_val)\n",
    "            oof_predictions[val_ind] = oof_preds\n",
    "\n",
    "            del x_val, y_val, xgb_val, model, oof_preds\n",
    "            _ = gc.collect()\n",
    "\n",
    "        # compute oof\n",
    "        score = amex_metric_mod(train[target], oof_predictions)\n",
    "        permutation_importances[feature] = score\n",
    "    \n",
    "        dump(permutation_importances, \"permutation_importances.pkl\")\n",
    "    \n",
    "    return permutation_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation_importances = permutation(train, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
