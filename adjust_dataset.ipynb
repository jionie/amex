{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(\n",
    "    path=\"\", \n",
    "    usecols=None\n",
    "):\n",
    "    # LOAD DATAFRAME\n",
    "    if usecols is not None: \n",
    "        df = pd.read_parquet(path, columns=usecols)\n",
    "    else: \n",
    "        df = pd.read_parquet(path)\n",
    "    \n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    df[\"customer_ID\"] = df[\"customer_ID\"].str[-16:]\n",
    "    \n",
    "    hex_to_int = lambda x: int(x, 16)\n",
    "    df[[\"customer_ID\"]] = df[[\"customer_ID\"]].applymap(lambda x: int(x, 16))\n",
    "    \n",
    "    df[\"customer_ID\"] = df[\"customer_ID\"].astype(\"int64\")\n",
    "    df[\"S_2\"] = pd.to_datetime(df[\"S_2\"])\n",
    "    \n",
    "    # SORT BY CUSTOMER AND DATE (so agg(\"last\") works correctly)\n",
    "    df = df.sort_values([\"customer_ID\", \"S_2\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # FILL NAN\n",
    "    print(\"shape of data:\", df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "shape of data: (5531451, 190)\n",
      "shape of data: (11363762, 190)\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "TRAIN_PATH = \"../input/amex-data-integer-dtypes-parquet-format/train.parquet\"\n",
    "train = load_file(path = TRAIN_PATH)\n",
    "\n",
    "TEST_PATH = \"../input/amex-data-integer-dtypes-parquet-format/test.parquet\"\n",
    "test = load_file(path = TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['int_cols.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cols = train.select_dtypes(include=[np.int8, np.int16, np.int32, np.int64]).columns.tolist()\n",
    "int_cols = [col for col in int_cols if col not in [\"customer_ID\"]]\n",
    "dump(int_cols, \"int_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3053463\n",
       "1       476208\n",
       "3       103975\n",
       "2       102479\n",
       "4       101466\n",
       "        ...   \n",
       "178          1\n",
       "176          1\n",
       "149          1\n",
       "142          1\n",
       "172          1\n",
       "Name: D_39, Length: 180, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"D_39\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert to nan\n",
    "train[train==-1] = np.nan\n",
    "test[test==-1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>0.342033</td>\n",
       "      <td>9</td>\n",
       "      <td>0.298571</td>\n",
       "      <td>0.028331</td>\n",
       "      <td>0.506896</td>\n",
       "      <td>0.793958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.340178</td>\n",
       "      <td>16</td>\n",
       "      <td>0.353684</td>\n",
       "      <td>0.026975</td>\n",
       "      <td>0.505335</td>\n",
       "      <td>0.795727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825231</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>0.356010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.448582</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.506290</td>\n",
       "      <td>0.530133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>0.378665</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443752</td>\n",
       "      <td>0.024322</td>\n",
       "      <td>0.509069</td>\n",
       "      <td>0.539285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>2017-07-22</td>\n",
       "      <td>0.416543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.463824</td>\n",
       "      <td>0.023064</td>\n",
       "      <td>0.505335</td>\n",
       "      <td>0.461935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919373</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_ID        S_2       P_2  D_39       B_1       B_2  \\\n",
       "0 -9223358381327749917 2017-03-31  0.342033     9  0.298571  0.028331   \n",
       "1 -9223358381327749917 2017-04-07  0.340178    16  0.353684  0.026975   \n",
       "2 -9223358381327749917 2017-05-23  0.356010     1  0.448582  0.026601   \n",
       "3 -9223358381327749917 2017-06-22  0.378665     1  0.443752  0.024322   \n",
       "4 -9223358381327749917 2017-07-22  0.416543     1  0.463824  0.023064   \n",
       "\n",
       "        R_1       S_3  D_41       B_3  ...  D_136  D_137  D_138  D_139  D_140  \\\n",
       "0  0.506896  0.793958   0.0  0.823765  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "1  0.505335  0.795727   0.0  0.825231  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "2  0.506290  0.530133   0.0  0.923707  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "3  0.509069  0.539285   0.0  0.915724  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "4  0.505335  0.461935   0.0  0.919373  ...    NaN    NaN    NaN    0.0    0.0   \n",
       "\n",
       "   D_141  D_142  D_143     D_144  D_145  \n",
       "0    0.0    NaN    0.0  0.004787    0.0  \n",
       "1    0.0    NaN    0.0  0.003442    0.0  \n",
       "2    0.0    NaN    0.0  0.003340    0.0  \n",
       "3    0.0    NaN    0.0  0.007556    0.0  \n",
       "4    0.0    NaN    0.0  0.005299    0.0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_observation(df):\n",
    "    \n",
    "    df[\"number_of_observations\"] = df.groupby(\"customer_ID\")[\"customer_ID\"].transform(\"count\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_observation(train)\n",
    "test = add_observation(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add first occurance flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_first_occurance(df):\n",
    "    \n",
    "    df[\"index\"] = df.index.tolist()\n",
    "    first_occurance_index = df[[\"customer_ID\", \"index\"]].groupby(\"customer_ID\").first()[\"index\"].tolist()\n",
    "    \n",
    "    df[\"first_occurance\"] = 0\n",
    "    df.loc[df[\"index\"].isin(first_occurance_index), \"first_occurance\"] = 1\n",
    "    \n",
    "    df = df.drop([\"index\"], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_first_occurance(train)\n",
    "test = add_first_occurance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nan clusters first\n",
    "cols = sorted(train.columns[2:].tolist())\n",
    "nas = train[cols].isna().sum(axis=0).reset_index(name=\"NA_count\")\n",
    "nas[\"group_count\"] = nas.loc[nas.NA_count > 0].groupby(\"NA_count\").transform(\"count\")\n",
    "clusters = nas.loc[nas.group_count > 10].sort_values([\"NA_count\",\"index\"]).groupby(\"NA_count\")[\"index\"].apply(list).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_16',\n",
       " 'B_19',\n",
       " 'B_2',\n",
       " 'B_20',\n",
       " 'B_22',\n",
       " 'B_26',\n",
       " 'B_27',\n",
       " 'B_3',\n",
       " 'B_30',\n",
       " 'B_33',\n",
       " 'B_38',\n",
       " 'D_41',\n",
       " 'D_54']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_113\n",
      "D_114\n",
      "D_116\n",
      "D_117\n",
      "D_120\n",
      "D_122\n",
      "D_123\n",
      "D_124\n",
      "D_125\n"
     ]
    }
   ],
   "source": [
    "for col in clusters[2]:\n",
    "    if col in int_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_0_nan(df, cluster):\n",
    "    \n",
    "    type_0_nan_customers = df.loc[df[cluster[0]].isnull(), \"customer_ID\"].unique().tolist()\n",
    "    df.loc[df[\"customer_ID\"].isin(type_0_nan_customers), cluster] = df.loc[df[\"customer_ID\"].isin(type_0_nan_customers), cluster].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = process_type_0_nan(train, clusters[0])\n",
    "# test = process_type_0_nan(test, clusters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_1_nan(df, cluster):\n",
    "    \n",
    "    type_1_nan_customers_group_0 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 0), \"customer_ID\"].unique().tolist()\n",
    "    type_1_nan_customers_group_1 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 1), \"customer_ID\"].unique().tolist()\n",
    "    \n",
    "    # fill group 1 by 0\n",
    "    df.loc[df[\"customer_ID\"].isin(type_1_nan_customers_group_1), cluster] = \\\n",
    "        df.loc[df[\"customer_ID\"].isin(type_1_nan_customers_group_1), cluster].fillna(0)\n",
    "    \n",
    "    # fill group 0 by mean of t - 1 and t + 1\n",
    "    ffill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    bfill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    \n",
    "    ffill[cluster] = ffill[cluster].fillna(method=\"ffill\")\n",
    "    bfill[cluster] = bfill[cluster].fillna(method=\"bfill\")\n",
    "    \n",
    "    df.loc[df[\"customer_ID\"].isin(type_1_nan_customers_group_0), cluster] = \\\n",
    "        (ffill.loc[ffill[\"customer_ID\"].isin(type_1_nan_customers_group_0), cluster] + \\\n",
    "         bfill.loc[bfill[\"customer_ID\"].isin(type_1_nan_customers_group_0), cluster]) / 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = process_type_1_nan(train, clusters[1])\n",
    "# test = process_type_1_nan(test, clusters[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_type_2_nan(df, cluster):\n",
    "    \n",
    "    type_2_nan_customers_group_0 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 0), \"customer_ID\"].unique().tolist()\n",
    "    type_2_nan_customers_group_1 = df.loc[(df[cluster[0]].isnull()) & (df[\"first_occurance\"] == 1), \"customer_ID\"].unique().tolist()\n",
    "    \n",
    "    ffill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    bfill = df[[\"customer_ID\"] + cluster].copy()\n",
    "    \n",
    "    ffill[cluster] = ffill[cluster].fillna(method=\"ffill\")\n",
    "    bfill[cluster] = bfill[cluster].fillna(method=\"bfill\")\n",
    "    \n",
    "    # fill group 1 by bfill\n",
    "    df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster] = \\\n",
    "        bfill.loc[bfill[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster]\n",
    "\n",
    "    # fill group 1 by 0\n",
    "    df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster] = \\\n",
    "        df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_1), cluster].fillna(0)\n",
    "    \n",
    "    # fill group 0 by mean of fill and bfill\n",
    "    df.loc[df[\"customer_ID\"].isin(type_2_nan_customers_group_0), cluster] = \\\n",
    "        (ffill.loc[ffill[\"customer_ID\"].isin(type_2_nan_customers_group_0), cluster] + \\\n",
    "         bfill.loc[bfill[\"customer_ID\"].isin(type_2_nan_customers_group_0), cluster]) / 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = process_type_2_nan(train, clusters[2])\n",
    "# test = process_type_2_nan(test, clusters[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_id(df):\n",
    "    \n",
    "    df[\"time_id\"] = df.groupby([\"customer_ID\"]).cumcount()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_time_id(train)\n",
    "test = add_time_id(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add end_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_year_month(df):\n",
    "    \n",
    "    df[\"end_year_month\"] = df[\"S_2\"].dt.to_period(\"M\")\n",
    "    df[\"end_year_month\"] = df.groupby(\"customer_ID\")[\"end_year_month\"].transform(\"last\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_end_year_month(train)\n",
    "test = add_end_year_month(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-04    5719469\n",
       "2019-10    5644293\n",
       "Freq: M, Name: end_year_month, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"end_year_month\"] .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_fillna.parquet\")\n",
    "# test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_fillna.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_base.parquet\")\n",
    "test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_base.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = load(\"int_cols.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_fillna.parquet\")\n",
    "# test = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_fillna.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_base.parquet\")\n",
    "test = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_base.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_features = [\n",
    "    \"D_42\",\n",
    "    \"D_52\",\n",
    "    \"D_59\",\n",
    "    \"D_79\",\n",
    "    \"D_93\",\n",
    "    \"D_105\",\n",
    "    \"D_116\",\n",
    "    \"D_122\",\n",
    "    \"D_130\",\n",
    "    \"D_133\",\n",
    "    \"D_142\",\n",
    "    \"S_11\",\n",
    "    \"B_36\"\n",
    "]\n",
    "\n",
    "outlier_features = [\n",
    "    \"D_106\",\n",
    "    \"S_23\",\n",
    "    \"B_10\",\n",
    "]\n",
    "outlier_features = [feature for feature in outlier_features if feature not in int_cols]\n",
    "\n",
    "test_base_outlier_features = [\n",
    "    \"D_102\",\n",
    "    \"D_109\",\n",
    "    \"D_144\",\n",
    "    \"B_6\",\n",
    "    \"B_40\"\n",
    "]\n",
    "test_base_outlier_features = [feature for feature in test_base_outlier_features if feature not in int_cols]\n",
    "\n",
    "test_public_base_outlier_features = [\n",
    "    \"D_69\"\n",
    "]\n",
    "test_public_base_outlier_features = [feature for feature in test_public_base_outlier_features if feature not in int_cols]\n",
    "\n",
    "test_private_base_outlier_features = [\n",
    "    \"S_18\"\n",
    "]\n",
    "test_private_base_outlier_features = [feature for feature in test_private_base_outlier_features if feature not in int_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public_end_year_month = test[\"end_year_month\"].iloc[0]\n",
    "test_private_end_year_month = test[\"end_year_month\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_59\n",
      "D_79\n",
      "D_93\n",
      "D_116\n",
      "D_122\n",
      "S_11\n"
     ]
    }
   ],
   "source": [
    "for col in shift_features:\n",
    "    if col in int_cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift features\n",
    "test.loc[test[\"end_year_month\"] == test_public_end_year_month, shift_features] = \\\n",
    "    test.loc[test[\"end_year_month\"] == test_public_end_year_month, shift_features] - \\\n",
    "    np.nanmean(test.loc[test[\"end_year_month\"] == test_public_end_year_month, shift_features], axis=0) + \\\n",
    "    np.nanmean(train[shift_features], axis=0)\n",
    "\n",
    "test.loc[test[\"end_year_month\"] == test_private_end_year_month, shift_features] = \\\n",
    "    test.loc[test[\"end_year_month\"] == test_private_end_year_month, shift_features] - \\\n",
    "    np.nanmean(test.loc[test[\"end_year_month\"] == test_private_end_year_month, shift_features], axis=0) + \\\n",
    "    np.nanmean(train[shift_features], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # int shift_features, floor\n",
    "# int_shift_features = [feature for feature in shift_features if feature in int_cols]\n",
    "\n",
    "# test[int_shift_features] = test[int_shift_features].fillna(-100)\n",
    "# test[int_shift_features] = np.floor(test[int_shift_features]).astype(int)\n",
    "\n",
    "# test[test==-100] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # float shift_features\n",
    "# float_shift_features = [feature for feature in shift_features if feature not in int_cols]\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_public_end_year_month, float_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_public_end_year_month, float_shift_features] - \\\n",
    "#     np.nanmean(test.loc[test[\"end_year_month\"] == test_public_end_year_month, float_shift_features], axis=0) + \\\n",
    "#     np.nanmean(train[float_shift_features], axis=0)\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_private_end_year_month, float_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_private_end_year_month, float_shift_features] - \\\n",
    "#     np.nanmean(test.loc[test[\"end_year_month\"] == test_private_end_year_month, float_shift_features], axis=0) + \\\n",
    "#     np.nanmean(train[float_shift_features], axis=0)\n",
    "\n",
    "# # int shift_features\n",
    "# int_shift_features = [feature for feature in shift_features if feature in int_cols]\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_public_end_year_month, int_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_public_end_year_month, int_shift_features] - \\\n",
    "#     np.floor(np.nanmean(test.loc[test[\"end_year_month\"] == test_public_end_year_month, int_shift_features], axis=0)).astype(int) + \\\n",
    "#     np.floor(np.nanmean(train[int_shift_features], axis=0)).astype(int)\n",
    "\n",
    "# test.loc[test[\"end_year_month\"] == test_private_end_year_month, int_shift_features] = \\\n",
    "#     test.loc[test[\"end_year_month\"] == test_private_end_year_month, int_shift_features] - \\\n",
    "#     np.floor(np.nanmean(test.loc[test[\"end_year_month\"] == test_private_end_year_month, int_shift_features], axis=0)).astype(int) + \\\n",
    "#     np.floor(np.nanmean(train[int_shift_features], axis=0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_shifted.parquet\")\n",
    "test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_shifted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_shifted.parquet\")\n",
    "# test = pd.read_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_shifted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_public = test.loc[test[\"end_year_month\"] == test_public_end_year_month]\n",
    "# test_private = test.loc[test[\"end_year_month\"] == test_private_end_year_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # outlier_features\n",
    "# all_data = pd.concat([train, test], axis=0)\n",
    "\n",
    "# outlier_features_mean, outlier_features_std = np.nanmean(all_data[outlier_features], axis=0), np.nanstd(all_data[outlier_features], axis=0)\n",
    "\n",
    "# train[outlier_features] = np.clip(train[outlier_features], \n",
    "#                                   outlier_features_mean - 3 * outlier_features_std, \n",
    "#                                   outlier_features_mean + 3 * outlier_features_std\n",
    "#                                  )\n",
    "# test[outlier_features] = np.clip(test[outlier_features], \n",
    "#                                  outlier_features_mean - 3 * outlier_features_std, \n",
    "#                                  outlier_features_mean + 3 * outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_base_outlier_features\n",
    "# test_base_outlier_features_mean, test_base_outlier_features_std = \\\n",
    "#     np.nanmean(test[test_base_outlier_features], axis=0), np.nanstd(test[test_base_outlier_features], axis=0)\n",
    "\n",
    "# train[test_base_outlier_features] = np.clip(train[test_base_outlier_features], \n",
    "#                                   test_base_outlier_features_mean - 3 * test_base_outlier_features_std, \n",
    "#                                   test_base_outlier_features_mean + 3 * test_base_outlier_features_std\n",
    "#                                  )\n",
    "# test[test_base_outlier_features] = np.clip(test[test_base_outlier_features], \n",
    "#                                  test_base_outlier_features_mean - 3 * test_base_outlier_features_std, \n",
    "#                                  test_base_outlier_features_mean + 3 * test_base_outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_public_base_outlier_features\n",
    "# test_public_base_outlier_features_mean, test_public_base_outlier_features_std = \\\n",
    "#     np.nanmean(test_public[test_public_base_outlier_features], axis=0), np.nanstd(test_public[test_public_base_outlier_features], axis=0)\n",
    "\n",
    "# train[test_public_base_outlier_features] = np.clip(train[test_public_base_outlier_features], \n",
    "#                                   test_public_base_outlier_features_mean - 3 * test_public_base_outlier_features_std, \n",
    "#                                   test_public_base_outlier_features_mean + 3 * test_public_base_outlier_features_std\n",
    "#                                  )\n",
    "# test[test_public_base_outlier_features] = np.clip(test[test_public_base_outlier_features], \n",
    "#                                  test_public_base_outlier_features_mean - 3 * test_public_base_outlier_features_std, \n",
    "#                                  test_public_base_outlier_features_mean + 3 * test_public_base_outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_private_base_outlier_features\n",
    "# test_private_base_outlier_features_mean, test_private_base_outlier_features_std = \\\n",
    "#     np.nanmean(test_private[test_private_base_outlier_features], axis=0), np.nanstd(test_private[test_private_base_outlier_features], axis=0)\n",
    "\n",
    "# train[test_private_base_outlier_features] = np.clip(train[test_private_base_outlier_features], \n",
    "#                                   test_private_base_outlier_features_mean - 3 * test_private_base_outlier_features_std, \n",
    "#                                   test_private_base_outlier_features_mean + 3 * test_private_base_outlier_features_std\n",
    "#                                  )\n",
    "# test[test_private_base_outlier_features] = np.clip(test[test_private_base_outlier_features], \n",
    "#                                  test_private_base_outlier_features_mean - 3 * test_private_base_outlier_features_std, \n",
    "#                                  test_private_base_outlier_features_mean + 3 * test_private_base_outlier_features_std\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.051987506, 0.18215398)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_base_outlier_features_mean[1], test_base_outlier_features_std[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/train_clipped.parquet\")\n",
    "# test.to_parquet(\"../input/amex-data-integer-dtypes-parquet-format/test_clipped.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
