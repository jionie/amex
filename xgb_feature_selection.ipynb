{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from shaphypetune import BoostSearch, BoostRFE, BoostRFA, BoostBoruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../input/train_base.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_hat, y_true):\n",
    "    return 'amex_metric', amex_metric_mod(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_folds = 5\n",
    "\n",
    "exclude_features = []\n",
    "\n",
    "exclude_features += [\n",
    "    \"customer_ID\", \n",
    "    \"target\",\n",
    "    \"number_of_observations\",\n",
    "]\n",
    "features = [col for col in train.columns if col not in exclude_features]\n",
    "target = \"target\"\n",
    "cat_features_base = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "] \n",
    "cat_features = [\n",
    "    \"{}_last\".format(feature) for feature in cat_features_base\n",
    "]\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(\n",
    "    n_splits=n_folds, \n",
    "    shuffle=True, \n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "fold_features = []\n",
    "\n",
    "for fold,(trn_ind, val_ind) in enumerate(kfold.split(train, train[target])):\n",
    "    \n",
    "    print(\"RFE for fold {}\".format(fold))\n",
    "    \n",
    "    x_train= train.loc[trn_ind, features]\n",
    "    y_train= train.loc[trn_ind, target]\n",
    "    x_val = train.loc[val_ind, features]\n",
    "    y_val = train.loc[val_ind, target]\n",
    "    \n",
    "    estimator = xgb.XGBRegressor(\n",
    "        max_depth=4, \n",
    "        learning_rate=0.05, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.6, \n",
    "        eval_metric=\"logloss\",\n",
    "        objective=\"binary:logistic\",\n",
    "        tree_method=\"gpu_hist\",\n",
    "        gpu_id=1,\n",
    "        predictor=\"gpu_predictor\",\n",
    "        random_state=seed\n",
    "    )\n",
    "    model = BoostRFE(  \n",
    "        estimator,                              # LGBModel or XGBModel\n",
    "        min_features_to_select=None,            # the minimum number of features to be selected  \n",
    "        step=40,                                 # number of features to remove at each iteration  \n",
    "        param_grid=None,                        # parameters to be optimized  \n",
    "        greater_is_better=False,                # minimize or maximize the monitored score  \n",
    "        importance_type=\"shap_importances\",     # which importance measure to use: default or shap  \n",
    "        train_importance=False,                 # where to compute the shap feature importance  \n",
    "        n_iter=None,                            # number of sampled parameter configurations  \n",
    "        sampling_seed=seed,                     # the seed used for parameter sampling  \n",
    "        verbose=1,                              # verbosity mode  \n",
    "        n_jobs=None                             # number of jobs to run in parallel  \n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        x_train, \n",
    "        y_train, \n",
    "        eval_set=[(x_val, y_val)], \n",
    "        early_stopping_rounds=6,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    fold_features.append(model.support_)\n",
    "    \n",
    "    del x_train, y_train, x_val, y_val, estimator, model\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_features = load(\"feature_mask.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ True,  True,  True, ...,  True,  True, False]),\n",
       " array([ True,  True,  True, ...,  True,  True, False]),\n",
       " array([False,  True,  True, ..., False, False, False]),\n",
       " array([False,  True,  True, ..., False, False, False]),\n",
       " array([False,  True,  True, ...,  True,  True, False])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(fold_features[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(fold_features, \"feature_mask.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_features = np.stack(fold_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_features = fold_features.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 1. , 1. , ..., 0.6, 0.6, 0. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_idxes = [feature_idx for feature_idx in range(len(fold_features)) if fold_features[feature_idx] > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_feature_idxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selected_feature_idxes.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(selected_feature_idxes, \"selected_feature_idxes.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
